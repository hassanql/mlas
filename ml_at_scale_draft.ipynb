{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BniCmmVfRA4"
      },
      "source": [
        "## Practical 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OptYxFpOf0Ig"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JWzS0FlXq8zI"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import csv\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFz9x33bf3sI"
      },
      "source": [
        "### Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDd6KcPca5Eb",
        "outputId": "07cccffb-7302-49a5-8039-a8fdd67ed4ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting download of https://files.grouplens.org/datasets/movielens/ml-32m.zip...\n",
            "File already downloaded or extracted. Skipping download.\n",
            "'ml-32m' already exists. Skipping unzip.\n",
            "\n",
            "Contents of ml-32m:\n",
            "total 934187\n",
            "-rw-rw-r-- 1 hassanh people       178 Oct 13  2023 checksums.txt\n",
            "-rw-rw-r-- 1 hassanh people   1950748 Oct 13  2023 links.csv\n",
            "-rw-rw-r-- 1 hassanh people   4242926 Oct 13  2023 movies.csv\n",
            "-rw-rw-r-- 1 hassanh people 877076222 Oct 13  2023 ratings.csv\n",
            "-rw-rw-r-- 1 hassanh people      9227 Oct 13  2023 README.txt\n",
            "-rw-rw-r-- 1 hassanh people  72353890 Oct 13  2023 tags.csv\n"
          ]
        }
      ],
      "source": [
        "url = \"https://files.grouplens.org/datasets/movielens/ml-32m.zip\"\n",
        "zip_file = \"ml-32m.zip\"\n",
        "extract_folder = \"ml-32m\"\n",
        "\n",
        "print(f\"Starting download of {url}...\")\n",
        "\n",
        "# Download only if not already downloaded\n",
        "if not os.path.exists(zip_file) and not os.path.exists(extract_folder):\n",
        "    !wget -q $url\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"File already downloaded or extracted. Skipping download.\")\n",
        "\n",
        "# Extract only if not already extracted\n",
        "if not os.path.exists(extract_folder):\n",
        "    print(f\"Unzipping {zip_file}...\")\n",
        "    !unzip -q $zip_file\n",
        "    print(f\"Successfully unzipped to '{extract_folder}' folder.\")\n",
        "else:\n",
        "    print(f\"'{extract_folder}' already exists. Skipping unzip.\")\n",
        "\n",
        "# List contents\n",
        "if os.path.exists(extract_folder):\n",
        "    print(f\"\\nContents of {extract_folder}:\")\n",
        "    !ls -l $extract_folder\n",
        "else:\n",
        "    print(f\"Error: Folder '{extract_folder}' not found after extraction.\")\n",
        "\n",
        "# Clean up the zip file if it still exists\n",
        "if os.path.exists(zip_file):\n",
        "    print(f\"\\nCleaning up {zip_file}...\")\n",
        "    os.remove(zip_file)\n",
        "    print(\"Zip file removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA68Il-Cf9kw"
      },
      "source": [
        "### Data Structure Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_r55pcsccNRT"
      },
      "outputs": [],
      "source": [
        "class RatingsData:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "\n",
        "        # Mappings\n",
        "        self.user_id_to_idx = {}\n",
        "        self.idx_to_user_id = []\n",
        "        self.movie_id_to_idx = {}\n",
        "        self.idx_to_movie_id = []\n",
        "\n",
        "        # Data\n",
        "        self.data_by_user = []\n",
        "        self.data_by_movie = []\n",
        "\n",
        "    def load(self):\n",
        "        user_set = set()\n",
        "        movie_set = set()\n",
        "\n",
        "        # First pass: collect all unique IDs\n",
        "        with open(self.file_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # skip header\n",
        "            for row in reader:\n",
        "                user_set.add(int(row[0]))\n",
        "                movie_set.add(int(row[1]))\n",
        "\n",
        "        # creating mappings\n",
        "        self.idx_to_user_id = sorted(list(user_set))\n",
        "        self.idx_to_movie_id =sorted(list(movie_set))\n",
        "\n",
        "        self.user_id_to_idx = {uid: i for i, uid in enumerate(self.idx_to_user_id)}\n",
        "        self.movie_id_to_idx = {mid: i for i, mid in enumerate(self.idx_to_movie_id)}\n",
        "\n",
        "        # initializing data lists\n",
        "        self.data_by_user = [[] for _ in range(len(self.idx_to_user_id))]\n",
        "        self.data_by_movie = [[] for _ in range(len(self.idx_to_movie_id))]\n",
        "\n",
        "        # fill ratings\n",
        "        with open(self.file_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader) # skip header\n",
        "            for row in reader:\n",
        "                user_id = int(row[0])\n",
        "                movie_id = int(row[1])\n",
        "                rating = float(row[2])\n",
        "\n",
        "                u_idx = self.user_id_to_idx[user_id]\n",
        "                m_idx = self.movie_id_to_idx[movie_id]\n",
        "\n",
        "                self.data_by_user[u_idx].append((movie_id, rating))\n",
        "                self.data_by_movie[m_idx].append((user_id, rating))\n",
        "\n",
        "\n",
        "    def get_user_ratings(self, user_id):\n",
        "        u_idx = self.user_id_to_idx[user_id]\n",
        "        return self.data_by_user[u_idx]\n",
        "\n",
        "    def get_movie_ratings(self, movie_id):\n",
        "        m_idx = self.movie_id_to_idx[movie_id]\n",
        "        return self.data_by_movie[m_idx]\n",
        "\n",
        "    def num_users(self):\n",
        "        return len(self.idx_to_user_id)\n",
        "\n",
        "    def num_movies(self):\n",
        "        return len(self.idx_to_movie_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXGAKQkCgc_5"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sXv8PhtQcn-v"
      },
      "outputs": [],
      "source": [
        "file_path = \"ml-32m/ratings.csv\"\n",
        "data = RatingsData(file_path)\n",
        "data.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ut6ve5xGilcY"
      },
      "outputs": [],
      "source": [
        "data.get_movie_ratings(296)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T4mcb6k9jMct"
      },
      "outputs": [],
      "source": [
        "data.get_user_ratings(296)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk16I3HLg4sB"
      },
      "source": [
        "### Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYWjZIAfl-QS"
      },
      "outputs": [],
      "source": [
        "def plot_rating_distribution(ratings_data):\n",
        "    \"\"\"\n",
        "    Plot rating distribution with bars centered on the actual rating values.\n",
        "    ratings_data: instance of RatingsData after load()\n",
        "    \"\"\"\n",
        "    # Collect all ratings into a NumPy array\n",
        "    all_ratings = []\n",
        "    for user_ratings in ratings_data.data_by_user:\n",
        "        for _, rating in user_ratings:\n",
        "            all_ratings.append(rating)\n",
        "    all_ratings = np.array(all_ratings)\n",
        "\n",
        "    # Define rating values (centers)\n",
        "    rating_values = np.arange(0.5, 5.1, 0.5)  # 0.5, 1.0, ..., 5.0\n",
        "    counts = np.array([np.sum(all_ratings == r) for r in rating_values])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(rating_values, counts, width=0.4, color='skyblue', edgecolor='black')\n",
        "    plt.xlabel(\"Rating\")\n",
        "    plt.ylabel(\"Number of Ratings\")\n",
        "    plt.title(\"Rating Distribution (Centered)\")\n",
        "    plt.xticks(rating_values)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykvkvDs3j_9A"
      },
      "outputs": [],
      "source": [
        "plot_rating_distribution(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyGI13Qumuys"
      },
      "outputs": [],
      "source": [
        "def plot_avg_rating_per_user(ratings_data):\n",
        "    \"\"\"\n",
        "    Plot the distribution of average ratings per user.\n",
        "    ratings_data: instance of RatingsData after load()\n",
        "    \"\"\"\n",
        "    # Compute average rating per user\n",
        "    avg_ratings = []\n",
        "    for user_ratings in ratings_data.data_by_user:\n",
        "        if len(user_ratings) > 0:\n",
        "            ratings = [r for _, r in user_ratings]\n",
        "            avg_ratings.append(np.mean(ratings))\n",
        "    avg_ratings = np.array(avg_ratings)\n",
        "\n",
        "    # Plot histogram\n",
        "    plt.figure(figsize=(8,5))\n",
        "    bins = np.arange(0.5, 5.1, 0.25)  # finer bins for averages\n",
        "    plt.hist(avg_ratings, bins=bins, color='skyblue', edgecolor='black')\n",
        "    plt.xlabel(\"Average Rating per User\")\n",
        "    plt.ylabel(\"Number of Users\")\n",
        "    plt.title(\"Distribution of Average Ratings per User\")\n",
        "    plt.xticks(np.arange(0.5, 5.1, 0.5))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayxsDStLrmIP"
      },
      "outputs": [],
      "source": [
        "plot_avg_rating_per_user(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QIDMdVrrpv9"
      },
      "outputs": [],
      "source": [
        "def plot_frequency_vs_degree(ratings_data):\n",
        "    \"\"\"\n",
        "    Log-log plot of frequency vs degree for movies and users.\n",
        "    Degree = number of ratings per movie/user.\n",
        "    Frequency = how many movies/users have that degree.\n",
        "    \"\"\"\n",
        "    # Movies\n",
        "    movie_degrees = np.array([len(r) for r in ratings_data.data_by_movie])\n",
        "    movie_deg_vals, movie_counts = np.unique(movie_degrees, return_counts=True)\n",
        "\n",
        "    # Users\n",
        "    user_degrees = np.array([len(r) for r in ratings_data.data_by_user])\n",
        "    user_deg_vals, user_counts = np.unique(user_degrees, return_counts=True)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.loglog(movie_deg_vals, movie_counts, marker='.', linestyle='none', color='blue', label='Movies')\n",
        "    plt.loglog(user_deg_vals, user_counts, marker='.', linestyle='none', color='orange', label='Users')\n",
        "\n",
        "    plt.xlabel(\"Degree (Number of Ratings)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Frequency vs Degree (Movies & Users) - Log-Log\")\n",
        "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.6)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwcx7oOMsA-r"
      },
      "outputs": [],
      "source": [
        "plot_frequency_vs_degree(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui2khDfGIR8X"
      },
      "source": [
        "## Practical 2:\n",
        "- download movielens dataset with 100k items for testing with faster loading time\n",
        "- split into training and test (90% 10%)\n",
        "- test the algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdK7wJ03hPX6"
      },
      "source": [
        "### Download 100k Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HxqTTC9sEbh"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Mount your Drive\u001b[39;00m\n\u001b[32m      4\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Mount your Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Path to your uploaded file\n",
        "# file_path = \"/content/drive/MyDrive/data/ratings_100k.csv\"\n",
        "\n",
        "# data_test = RatingsData(file_path)\n",
        "# data_test.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3TBV_W4hT05"
      },
      "source": [
        "### Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I1h73xFOMVG"
      },
      "outputs": [],
      "source": [
        "# Get the total number of users and movies from the dataset\n",
        "n_users = len(data_test.data_by_user)\n",
        "n_movies = len(data_test.data_by_movie)\n",
        "\n",
        "# Initialize empty lists to store train/test splits\n",
        "# Each user/movie will have separate lists for training and testing ratings\n",
        "data_by_user_train = [[] for _ in range(n_users)]\n",
        "data_by_user_test  = [[] for _ in range(n_users)]\n",
        "data_by_movie_train = [[] for _ in range(n_movies)]\n",
        "data_by_movie_test  = [[] for _ in range(n_movies)]\n",
        "\n",
        "# First pass: Split ratings by user (90% train, 10% test)\n",
        "# Loop through each user and randomly assign their ratings to train or test\n",
        "for i in range(n_users):\n",
        "  ratings = data_test.data_by_user[i]\n",
        "  for movie_id, rating in ratings:\n",
        "    # 90% probability of going to training set\n",
        "    if np.random.rand() < 0.9:\n",
        "      data_by_user_train[i].append((movie_id, rating))\n",
        "    else:\n",
        "      # 10% probability of going to test set\n",
        "      data_by_user_test[i].append((movie_id, rating))\n",
        "\n",
        "# Second pass: Reorganize the split data by movie\n",
        "# This creates movie-indexed versions of the train/test splits\n",
        "for i in range(n_users):\n",
        "    # Get the actual user ID from the index\n",
        "    user_id = data_test.idx_to_user_id[i]\n",
        "\n",
        "    # Add this user's training ratings to the movie-indexed training data\n",
        "    for movie_id, rating in data_by_user_train[i]:\n",
        "        m_idx = data_test.movie_id_to_idx[movie_id]\n",
        "        data_by_movie_train[m_idx].append((user_id, rating))\n",
        "\n",
        "    # Add this user's test ratings to the movie-indexed test data\n",
        "    for movie_id, rating in data_by_user_test[i]:\n",
        "        m_idx = data_test.movie_id_to_idx[movie_id]\n",
        "        data_by_movie_test[m_idx].append((user_id, rating))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o25FcHl2h-2b"
      },
      "source": [
        "### Confirming Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lr0anqVO2E7"
      },
      "outputs": [],
      "source": [
        "print(f\"number of items in users train set: {len(data_by_user_train)}\")\n",
        "print(f\"number of items in users test set: {len(data_by_user_test)}\")\n",
        "\n",
        "\n",
        "non_empty_users_train = sum(1 for u in data_by_user_train if len(u) > 0)\n",
        "non_empty_users_test = sum(1 for u in data_by_user_test if len(u) > 0)\n",
        "\n",
        "print(f\"Number of users with ratings in train set: {non_empty_users_train}\")\n",
        "print(f\"Number of users with ratings in test set: {non_empty_users_test}\")\n",
        "\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "print(f\"number of items in movies train set: {len(data_by_movie_train)}\")\n",
        "print(f\"number of items in movies test set: {len(data_by_movie_test)}\")\n",
        "\n",
        "non_empty_movies_train = sum(1 for u in data_by_movie_train if len(u) > 0)\n",
        "non_empty_movies_test = sum(1 for u in data_by_movie_test if len(u) > 0)\n",
        "\n",
        "print(f\"Number of movies with ratings in train set: {non_empty_movies_train}\")\n",
        "print(f\"Number of movies with ratings in test set: {non_empty_movies_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WORZaV36jBW7"
      },
      "source": [
        "### Training with Bias Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6R2dIInXPqH"
      },
      "outputs": [],
      "source": [
        "M = n_users\n",
        "N = n_movies\n",
        "\n",
        "lambd = 0.01    # update weight factor\n",
        "gamma = 0.01  # regularisation term for biases\n",
        "num_iters = 20\n",
        "\n",
        "# Initialise user & item biases lists\n",
        "user_biases = np.zeros((M))\n",
        "item_biases = np.zeros((N))\n",
        "\n",
        "# Calculate Global Mean\n",
        "global_mean = 0\n",
        "total_ratings = 0\n",
        "for m in range(M):\n",
        "    for (movie_idx, r) in data_by_user_train[m]:\n",
        "        global_mean += r\n",
        "        total_ratings += 1\n",
        "global_mean /= total_ratings\n",
        "\n",
        "# For plotting\n",
        "loss_history = []\n",
        "rmse_train_history = []\n",
        "rmse_test_history  = []\n",
        "\n",
        "# Start ALS loop\n",
        "for iter in range(num_iters):\n",
        "    # Update user biases\n",
        "    for m in range(M):\n",
        "        bias = 0 # initialise bias at 0\n",
        "        count = 0 # to keep track of number of ratings in each user list\n",
        "        for (movie_id, r) in data_by_user_train[m]:\n",
        "            movie_idx = data_test.movie_id_to_idx[movie_id]\n",
        "            bias += lambd * (r - global_mean - item_biases[movie_idx]) # sum of residuals multiplied by lambda\n",
        "            # bias += lambd * (r - item_biases[movie_idx]) # sum of residuals multiplied by lambda\n",
        "            count += 1                                                 # to keep track of how many ratings the user has\n",
        "\n",
        "        user_biases[m] = bias / (lambd * count + gamma) # gamma regularises the bias for users with few ratings\n",
        "\n",
        "    # Update item biases\n",
        "    for n in range(N):\n",
        "        bias = 0\n",
        "        count = 0\n",
        "        for (user_id, r) in data_by_movie_train[n]:\n",
        "            user_idx = data_test.user_id_to_idx[user_id]\n",
        "            bias += lambd * (r - global_mean - user_biases[user_idx])\n",
        "            # bias += lambd * (r - user_biases[user_idx])\n",
        "            count += 1\n",
        "\n",
        "        item_biases[n] = bias / (lambd * count + gamma)\n",
        "\n",
        "    # Training loss & RMSE\n",
        "    squared_error = 0\n",
        "    count = 0\n",
        "    for m in range(M):\n",
        "        for movie_id, r in data_by_user_train[m]:\n",
        "            # We assume predicted rating = global_mean + user_bias + item_bias\n",
        "            movie_idx = data_test.movie_id_to_idx[movie_id]\n",
        "            pred = global_mean + user_biases[m] + item_biases[movie_idx]\n",
        "            # pred = user_biases[m] + item_biases[movie_idx]\n",
        "            squared_error += (r - pred) ** 2\n",
        "            count += 1\n",
        "\n",
        "    reg_term = lambd * (np.sum(user_biases**2) + np.sum(item_biases**2))\n",
        "\n",
        "    rmse_train = np.sqrt(squared_error / count)\n",
        "    total_loss = squared_error + reg_term\n",
        "    rmse_train_history.append(rmse_train)\n",
        "    loss_history.append(total_loss)\n",
        "\n",
        "    # Compute test RMSE\n",
        "    squared_error_test = 0\n",
        "    count_test = 0\n",
        "    for m in range(M):\n",
        "        for movie_id, r in data_by_user_test[m]:\n",
        "            movie_idx = data_test.movie_id_to_idx[movie_id]\n",
        "            pred = user_biases[m] + item_biases[movie_idx]\n",
        "            squared_error_test += (r - pred) ** 2\n",
        "            count_test += 1\n",
        "    rmse_test = np.sqrt(squared_error_test / count_test)\n",
        "    rmse_test_history.append(rmse_test)\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_iters}: \"\n",
        "          f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "          f\"Loss = {squared_error:.2f}\")\n",
        "\n",
        "# --- Plot training loss ---\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(loss_history, marker='o')\n",
        "plt.title(\"Loss over iterations (Sum of Squared Errors)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# --- Plot training RMSE ---\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(rmse_train_history, marker='o', color='orange')\n",
        "plt.title(\"Training RMSE over iterations\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oESmiJCyIBFo"
      },
      "source": [
        "## Practical 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0VfPpjRYdTw"
      },
      "source": [
        "### 1. Prediction Formula\n",
        "\n",
        "The predicted rating ($\\hat{r}_{mn}$) for a user $m$ and item $n$.\n",
        "\n",
        "$$\n",
        "\\hat{r}_{mn} = \\mathbf{u}_m^T \\mathbf{v}_n + b_m^u + b_n^i\n",
        "$$\n",
        "\n",
        "* Corresponds to the `pred` variable in the code: `pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])`\n",
        "\n",
        "### 2. Loss Function (Negative Log Likelihood)\n",
        "\n",
        "The objective function to minimize.\n",
        "\n",
        "$$\n",
        "\\text{NLL} = -L = \\frac{\\lambda}{2} \\sum_{(m,n) \\in \\Omega} (r_{mn} - \\hat{r}_{mn})^2 + \\frac{\\tau}{2} \\left( \\sum_{m} ||\\mathbf{u}_m||^2 + \\sum_{n} ||\\mathbf{v}_n||^2 \\right) + \\frac{\\gamma}{2} \\left( \\sum_{m} (b_m^u)^2 + \\sum_{n} (b_n^i)^2 \\right)\n",
        "$$\n",
        "\n",
        "* Calculated in the code as:\n",
        "```python\n",
        "  nll = (lambda_reg/2) * squared_error + (tau/2) * reg_factors + (gamma/2) * reg_bias\n",
        "```\n",
        "\n",
        "### 3. RMSE (Root Mean Squared Error)\n",
        "\n",
        "The error metric used to evaluate the model.\n",
        "\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{\\frac{1}{|\\Omega|} \\sum_{(m,n) \\in \\Omega} (r_{mn} - \\hat{r}_{mn})^2}\n",
        "$$\n",
        "\n",
        "* Calculated as: `rmse_train = np.sqrt(squared_error / count)`\n",
        "\n",
        "### 4. ALS Updates\n",
        "\n",
        "The equations solved in the alternating least squares procedure.\n",
        "\n",
        "#### User Bias ($b_m^u$)\n",
        "\n",
        "$$\n",
        "b_m^u \\leftarrow \\frac{\\lambda \\sum_{n \\in \\Omega_m} (r_{mn} - b_n^i - \\mathbf{u}_m^T \\mathbf{v}_n)}{\\lambda |\\Omega_m| + \\gamma}\n",
        "$$\n",
        "\n",
        "* Code:\n",
        "```python\n",
        "  user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "```\n",
        "\n",
        "#### User Latent Factors ($\\mathbf{u}_m$)\n",
        "\n",
        "$$\n",
        "\\mathbf{u}_m \\leftarrow \\left( \\lambda \\sum_{n \\in \\Omega_m} \\mathbf{v}_n \\mathbf{v}_n^T + \\tau I \\right)^{-1} \\left( \\lambda \\sum_{n \\in \\Omega_m} \\mathbf{v}_n (r_{mn} - b_m^u - b_n^i) \\right)\n",
        "$$\n",
        "\n",
        "* Code:\n",
        "```python\n",
        "  A = lambda_reg * sum of outer products + tau * I\n",
        "  b = lambda_reg * sum of weighted item vectors\n",
        "  U[m] = np.linalg.solve(A, b)\n",
        "```\n",
        "\n",
        "#### Item Bias ($b_n^i$)\n",
        "\n",
        "$$\n",
        "b_n^i \\leftarrow \\frac{\\lambda \\sum_{m \\in \\Omega_n} (r_{mn} - b_m^u - \\mathbf{u}_m^T \\mathbf{v}_n)}{\\lambda |\\Omega_n| + \\gamma}\n",
        "$$\n",
        "\n",
        "* Code:\n",
        "```python\n",
        "  item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "```\n",
        "\n",
        "#### Item Latent Factors ($\\mathbf{v}_n$)\n",
        "\n",
        "$$\n",
        "\\mathbf{v}_n \\leftarrow \\left( \\lambda \\sum_{m \\in \\Omega_n} \\mathbf{u}_m \\mathbf{u}_m^T + \\tau I \\right)^{-1} \\left( \\lambda \\sum_{m \\in \\Omega_n} \\mathbf{u}_m (r_{mn} - b_m^u - b_n^i) \\right)\n",
        "$$\n",
        "\n",
        "* Code:\n",
        "```python\n",
        "  A = lambda_reg * sum of outer products + tau * I\n",
        "  b = lambda_reg * sum of weighted user vectors\n",
        "  V[n] = np.linalg.solve(A, b)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### Variables\n",
        "* $r_{mn}$: True rating for user $m$ and item $n$\n",
        "* $\\hat{r}_{mn}$: Predicted rating\n",
        "* $\\mathbf{u}_m \\in \\mathbb{R}^K$: User latent factor vector (code: `U[m]`)\n",
        "* $\\mathbf{v}_n \\in \\mathbb{R}^K$: Item latent factor vector (code: `V[n]`)\n",
        "* $b_m^u$: User bias (code: `user_biases[m]`)\n",
        "* $b_n^i$: Item bias (code: `item_biases[n]`)\n",
        "* $\\lambda$: Data term regularization (code: `lambda_reg`)\n",
        "* $\\tau$: Latent factor regularization (code: `tau`)\n",
        "* $\\gamma$: Bias regularization (code: `gamma`)\n",
        "* $K$: Number of latent factors (code: `K = 15`)\n",
        "* $\\Omega_m$: Set of items rated by user $m$\n",
        "* $\\Omega_n$: Set of users who rated item $n$\n",
        "* $I$: Identity matrix of size $K \\times K$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4SvNU86hqtQ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "K = 25               # Number of latent factors\n",
        "num_iters = 15       # Number of ALS iterations\n",
        "lambda_reg = 0.001   # Regularization for latent factors (U, V)\n",
        "tau = 0.05           # Regularization term for user/item vectors\n",
        "gamma = 0.001        # Regularization for biases\n",
        "\n",
        "\n",
        "M = len(data_by_user_train)   # Number of users\n",
        "N = len(data_by_movie_train)  # Number of movies\n",
        "\n",
        "# Calculate global mean\n",
        "all_ratings = []\n",
        "for m in range(M):\n",
        "    for movie_id, r in data_by_user_train[m]:\n",
        "        all_ratings.append(r)\n",
        "global_mean = np.mean(all_ratings)\n",
        "\n",
        "# Initialize biases and latent factors\n",
        "user_biases = np.zeros(M)\n",
        "item_biases = np.zeros(N)\n",
        "U = 0.1 * np.random.randn(M, K)   # User latent factors\n",
        "V = 0.1 * np.random.randn(N, K)   # Item latent factors\n",
        "\n",
        "# For plotting\n",
        "nll_history = []        # Negative log likelihood\n",
        "rmse_train_history = []\n",
        "rmse_test_history = []\n",
        "\n",
        "# ALS Loop\n",
        "for iter in range(num_iters):\n",
        "\n",
        "    # Update user biases and latent vectors\n",
        "    for m in range(M):\n",
        "        items = data_by_user_train[m]\n",
        "        if not items:\n",
        "            continue\n",
        "\n",
        "        # Update user bias\n",
        "        bias_sum = 0\n",
        "        for movie_id, r in items:\n",
        "            n = data_test.movie_id_to_idx[movie_id]\n",
        "            pred = global_mean + item_biases[n] + np.dot(U[m], V[n])\n",
        "            residual = r - pred\n",
        "            bias_sum += lambda_reg * residual\n",
        "        user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "\n",
        "        # Update user latent vector\n",
        "        A = np.zeros((K, K))\n",
        "        b = np.zeros(K)\n",
        "\n",
        "        for movie_id, r in items:\n",
        "            n = data_test.movie_id_to_idx[movie_id]\n",
        "            residual = r - global_mean - user_biases[m] - item_biases[n]\n",
        "\n",
        "            A += lambda_reg * np.outer(V[n], V[n])\n",
        "            b += lambda_reg * residual * V[n]\n",
        "\n",
        "        A += tau * np.eye(K)\n",
        "        U[m] = np.linalg.solve(A, b)\n",
        "\n",
        "    # Update item biases and latent vectors\n",
        "    for n in range(N):\n",
        "        users = data_by_movie_train[n]\n",
        "        if not users:\n",
        "            continue\n",
        "\n",
        "        # Update item bias\n",
        "        bias_sum = 0\n",
        "        for user_id, r in users:\n",
        "            m_idx = data_test.user_id_to_idx[user_id]\n",
        "            pred = global_mean + user_biases[m_idx] + np.dot(U[m_idx], V[n])\n",
        "            residual = r - pred\n",
        "            bias_sum += lambda_reg * residual\n",
        "        item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "\n",
        "        # Update item latent vector\n",
        "        A = np.zeros((K, K))\n",
        "        b = np.zeros(K)\n",
        "\n",
        "        for user_id, r in users:\n",
        "            m_idx = data_test.user_id_to_idx[user_id]\n",
        "            residual = r - global_mean - user_biases[m_idx] - item_biases[n]\n",
        "\n",
        "            A += lambda_reg * np.outer(U[m_idx], U[m_idx])\n",
        "            b += lambda_reg * residual * U[m_idx]\n",
        "\n",
        "        A += tau * np.eye(K)\n",
        "        V[n] = np.linalg.solve(A, b)\n",
        "\n",
        "    # Compute negative log likelihood (training)\n",
        "    squared_error = 0\n",
        "    count = 0\n",
        "    for m in range(M):\n",
        "        for movie_id, r in data_by_user_train[m]:\n",
        "            n = data_test.movie_id_to_idx[movie_id]\n",
        "            pred = global_mean + user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error += (r - pred) ** 2\n",
        "            count += 1\n",
        "\n",
        "    # Regularization terms\n",
        "    reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "    reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "    # Log likelihood formula from slides\n",
        "    log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "\n",
        "    # Negative log likelihood (negate to get NLL)\n",
        "    nll = -log_likelihood\n",
        "    nll_history.append(nll)\n",
        "\n",
        "    # Training RMSE\n",
        "    rmse_train = np.sqrt(squared_error / count)\n",
        "    rmse_train_history.append(rmse_train)\n",
        "\n",
        "    # Compute test RMSE\n",
        "    squared_error_test = 0\n",
        "    count_test = 0\n",
        "    for m in range(M):\n",
        "        for movie_id, r in data_by_user_test[m]:\n",
        "            n = data_test.movie_id_to_idx[movie_id]\n",
        "            pred = global_mean + user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error_test += (r - pred) ** 2\n",
        "            count_test += 1\n",
        "    rmse_test = np.sqrt(squared_error_test / count_test)\n",
        "    rmse_test_history.append(rmse_test)\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_iters}: \"\n",
        "          f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "          f\"NLL = {nll:.2f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(nll_history, marker='o', color='purple')\n",
        "plt.title(\"Negative Log Likelihood (Training)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Negative Log Likelihood\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(rmse_train_history, marker='o', color='orange')\n",
        "plt.title(\"Training RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(rmse_test_history, marker='o', color='green')\n",
        "plt.title(\"Test RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XsXQV65W3cS"
      },
      "source": [
        "### Finding best hyperparameters via Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYcA_DVXzXdF"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "# Fixed K value\n",
        "K = 25  # Number of latent factors\n",
        "\n",
        "# Values to search over\n",
        "lambda_reg_values = [0.0005, 0.001, 0.005]        # Regularization for likelihood\n",
        "tau_values = [0.03, 0.05, 0.1]                    # Regularization for latent factors\n",
        "gamma_values = [0.0005, 0.001, 0.005]             # Regularization for biases\n",
        "\n",
        "num_iters = 10  # Number of iterations for search\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = len(lambda_reg_values) * len(tau_values) * len(gamma_values)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GRID SEARCH FOR BEST HYPERPARAMETERS - ALS WITH LATENT FACTORS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"K (fixed): {K}\")\n",
        "print(f\"lambda_reg values: {lambda_reg_values}\")\n",
        "print(f\"tau values: {tau_values}\")\n",
        "print(f\"gamma values: {gamma_values}\")\n",
        "print(f\"Iterations per combination: {num_iters}\")\n",
        "print(f\"Total combinations to test: {total_combinations}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Dataset dimensions\n",
        "M = len(data_by_user_train)   # Number of users\n",
        "N = len(data_by_movie_train)  # Number of movies\n",
        "\n",
        "# SEARCH LOOP\n",
        "# Store results for each hyperparameter combination\n",
        "grid_search_results = []\n",
        "combination_num = 0\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for lambda_reg, tau, gamma in product(lambda_reg_values, tau_values, gamma_values):\n",
        "    combination_num += 1\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"COMBINATION {combination_num}/{total_combinations}\")\n",
        "    print(f\"lambda={lambda_reg}, tau={tau}, gamma={gamma}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Initialize biases and latent factors\n",
        "    user_biases = np.zeros(M)\n",
        "    item_biases = np.zeros(N)\n",
        "    U = (1.0 / np.sqrt(K)) * np.random.randn(M, K)   # User latent factors\n",
        "    V = (1.0 / np.sqrt(K)) * np.random.randn(N, K)   # Item latent factors\n",
        "\n",
        "    # Tracking metrics\n",
        "    nll_history = []\n",
        "    rmse_train_history = []\n",
        "    rmse_test_history = []\n",
        "\n",
        "    # ALS training loop\n",
        "    for iter in range(num_iters):\n",
        "\n",
        "        # Update user biases and latent vectors\n",
        "        for m in range(M):\n",
        "            items = data_by_user_train[m]\n",
        "            if not items:\n",
        "                continue\n",
        "\n",
        "            # Update bias\n",
        "            bias_sum = 0\n",
        "            for movie_id, r in items:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = item_biases[n] + np.dot(U[m], V[n])\n",
        "                residual = r - pred\n",
        "                bias_sum += lambda_reg * residual\n",
        "            user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "\n",
        "            # Update latent vector\n",
        "            A = np.zeros((K, K))\n",
        "            b = np.zeros(K)\n",
        "\n",
        "            for movie_id, r in items:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                residual = r - user_biases[m] - item_biases[n]\n",
        "\n",
        "                A += lambda_reg * np.outer(V[n], V[n])\n",
        "                b += lambda_reg * residual * V[n]\n",
        "\n",
        "            A += tau * np.eye(K)\n",
        "            U[m] = np.linalg.solve(A, b)\n",
        "\n",
        "        # Update item biases and latent vectors\n",
        "        for n in range(N):\n",
        "            users = data_by_movie_train[n]\n",
        "            if not users:\n",
        "                continue\n",
        "\n",
        "            # Update bias\n",
        "            bias_sum = 0\n",
        "            for user_id, r in users:\n",
        "                m_idx = data_test.user_id_to_idx[user_id]\n",
        "                pred = user_biases[m_idx] + np.dot(U[m_idx], V[n])\n",
        "                residual = r - pred\n",
        "                bias_sum += lambda_reg * residual\n",
        "            item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "\n",
        "            # Update latent vector\n",
        "            A = np.zeros((K, K))\n",
        "            b = np.zeros(K)\n",
        "\n",
        "            for user_id, r in users:\n",
        "                m_idx = data_test.user_id_to_idx[user_id]\n",
        "                residual = r - user_biases[m_idx] - item_biases[n]\n",
        "\n",
        "                A += lambda_reg * np.outer(U[m_idx], U[m_idx])\n",
        "                b += lambda_reg * residual * U[m_idx]\n",
        "\n",
        "            A += tau * np.eye(K)\n",
        "            V[n] = np.linalg.solve(A, b)\n",
        "\n",
        "        #  Compute training negative log likelihood\n",
        "        squared_error = 0\n",
        "        count = 0\n",
        "        for m in range(M):\n",
        "            for movie_id, r in data_by_user_train[m]:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "                squared_error += (r - pred) ** 2\n",
        "                count += 1\n",
        "\n",
        "        # Regularization terms\n",
        "        reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "        reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "        # Log likelihood formula\n",
        "        log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "        nll = -log_likelihood\n",
        "        nll_history.append(nll)\n",
        "\n",
        "        # Training RMSE\n",
        "        rmse_train = np.sqrt(squared_error / count)\n",
        "        rmse_train_history.append(rmse_train)\n",
        "\n",
        "        # Compute test RMSE\n",
        "        squared_error_test = 0\n",
        "        count_test = 0\n",
        "        for m in range(M):\n",
        "            for movie_id, r in data_by_user_test[m]:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "                squared_error_test += (r - pred) ** 2\n",
        "                count_test += 1\n",
        "        rmse_test = np.sqrt(squared_error_test / count_test) if count_test > 0 else float('inf')\n",
        "        rmse_test_history.append(rmse_test)\n",
        "\n",
        "        print(f\"  Iteration {iter+1}/{num_iters}: \"\n",
        "                  f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "                  f\"NLL = {nll:.2f}\")\n",
        "\n",
        "    # Store results for combination\n",
        "    final_train_rmse = rmse_train_history[-1]\n",
        "    final_test_rmse = rmse_test_history[-1]\n",
        "    final_nll = nll_history[-1]\n",
        "\n",
        "    grid_search_results.append({'lambda_reg': lambda_reg, 'tau': tau, 'gamma': gamma,\n",
        "        'final_train_rmse': final_train_rmse, 'final_test_rmse': final_test_rmse, 'final_nll': final_nll,\n",
        "        'nll_history': nll_history.copy(), 'rmse_train_history': rmse_train_history.copy(), 'rmse_test_history': rmse_test_history.copy()})\n",
        "\n",
        "    print(f\"  FINAL: Train RMSE = {final_train_rmse:.4f}, \"\n",
        "          f\"Test RMSE = {final_test_rmse:.4f}, NLL = {final_nll:.2f}\")\n",
        "\n",
        "# ANALYZE\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GRID SEARCH RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Lambda':<10} {'Tau':<8} {'Gamma':<10} {'Train RMSE':<12} {'Test RMSE':<12} {'NLL':<12}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for result in grid_search_results:\n",
        "    print(f\"{result['lambda_reg']:<10.4f} {result['tau']:<8.4f} \"\n",
        "          f\"{result['gamma']:<10.4f} {result['final_train_rmse']:<12.4f} \"\n",
        "          f\"{result['final_test_rmse']:<12.4f} {result['final_nll']:<12.2f}\")\n",
        "\n",
        "# Find best based on test RMSE (primary metric)\n",
        "best_result = min(grid_search_results, key=lambda x: x['final_test_rmse'])\n",
        "\n",
        "# Also find best based on NLL (for reference)\n",
        "best_nll_result = min(grid_search_results, key=lambda x: x['final_nll'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEST HYPERPARAMETERS (Based on Test RMSE)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"lambda_reg: {best_result['lambda_reg']}\")\n",
        "print(f\"tau: {best_result['tau']}\")\n",
        "print(f\"gamma: {best_result['gamma']}\")\n",
        "print(f\"Final Train RMSE: {best_result['final_train_rmse']:.4f}\")\n",
        "print(f\"Final Test RMSE: {best_result['final_test_rmse']:.4f}\")\n",
        "print(f\"Final NLL: {best_result['final_nll']:.2f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if best_nll_result != best_result:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BEST HYPERPARAMETERS (Based on NLL)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"lambda_reg: {best_nll_result['lambda_reg']}\")\n",
        "    print(f\"tau: {best_nll_result['tau']}\")\n",
        "    print(f\"gamma: {best_nll_result['gamma']}\")\n",
        "    print(f\"Final Train RMSE: {best_nll_result['final_train_rmse']:.4f}\")\n",
        "    print(f\"Final Test RMSE: {best_nll_result['final_test_rmse']:.4f}\")\n",
        "    print(f\"Final NLL: {best_nll_result['final_nll']:.2f}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# VISUALIZATION: TOP 5 CONFIGURATIONS\n",
        "\n",
        "# Sort by test RMSE and get top 5\n",
        "top_5_results = sorted(grid_search_results, key=lambda x: x['final_test_rmse'])[:5]\n",
        "\n",
        "fig, axes = plt.subplots(3, 5, figsize=(25, 12))\n",
        "\n",
        "for idx, result in enumerate(top_5_results):\n",
        "    # Plot NLL\n",
        "    axes[0, idx].plot(result['nll_history'], marker='o', color='purple', linewidth=2)\n",
        "    axes[0, idx].set_title(f\"Rank {idx+1}: NLL\\nλ={result['lambda_reg']:.4f}, \"\n",
        "                           f\"τ={result['tau']:.4f}, γ={result['gamma']:.4f}\", fontsize=9)\n",
        "    axes[0, idx].set_xlabel(\"Iteration\")\n",
        "    axes[0, idx].set_ylabel(\"NLL\")\n",
        "    axes[0, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot Training RMSE\n",
        "    axes[1, idx].plot(result['rmse_train_history'], marker='o', color='orange', linewidth=2)\n",
        "    axes[1, idx].set_title(f\"Train RMSE: {result['final_train_rmse']:.4f}\", fontsize=10)\n",
        "    axes[1, idx].set_xlabel(\"Iteration\")\n",
        "    axes[1, idx].set_ylabel(\"RMSE\")\n",
        "    axes[1, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot Test RMSE\n",
        "    axes[2, idx].plot(result['rmse_test_history'], marker='o', color='green', linewidth=2)\n",
        "    axes[2, idx].set_title(f\"Test RMSE: {result['final_test_rmse']:.4f}\", fontsize=10, fontweight='bold')\n",
        "    axes[2, idx].set_xlabel(\"Iteration\")\n",
        "    axes[2, idx].set_ylabel(\"RMSE\")\n",
        "    axes[2, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Highlight best configuration with red border\n",
        "    if result == best_result:\n",
        "        for ax in axes[:, idx]:\n",
        "            for spine in ax.spines.values():\n",
        "                spine.set_edgecolor('red')\n",
        "                spine.set_linewidth(3)\n",
        "\n",
        "plt.suptitle(\"Top 5 Hyperparameter Configurations (Ranked by Test RMSE)\",\n",
        "             fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Best Hyperparameters (from grid search with K={K})\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\"\"\n",
        "K = {K}\n",
        "num_iters = 10\n",
        "lambda_reg = {best_result['lambda_reg']}\n",
        "tau = {best_result['tau']}\n",
        "gamma = {best_result['gamma']}\n",
        "\n",
        "\"\"\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wsq9cay4Q9S"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "\n",
        "K = 25  # Number of latent factors\n",
        "\n",
        "# Define the values to search over\n",
        "lambda_reg_values = [0.01, 0.1, 0.2, 0.5]        # Regularization for likelihood\n",
        "tau_values = [0.01, 0.1, 0.2]                    # Regularization for latent factors\n",
        "gamma_values = [0.5, 1, 2]             # Regularization for biases\n",
        "\n",
        "num_iters = 10  # Fixed number of iterations for grid search\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = len(lambda_reg_values) * len(tau_values) * len(gamma_values)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GRID SEARCH FOR BEST HYPERPARAMETERS - ALS WITH LATENT FACTORS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"K (fixed): {K}\")\n",
        "print(f\"lambda_reg values: {lambda_reg_values}\")\n",
        "print(f\"tau values: {tau_values}\")\n",
        "print(f\"gamma values: {gamma_values}\")\n",
        "print(f\"Iterations per combination: {num_iters}\")\n",
        "print(f\"Total combinations to test: {total_combinations}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Get dataset dimensions\n",
        "M = len(data_by_user_train)   # Number of users\n",
        "N = len(data_by_movie_train)  # Number of movies\n",
        "\n",
        "# GRID SEARCH LOOP\n",
        "# Store results for each hyperparameter combination\n",
        "grid_search_results = []\n",
        "combination_num = 0\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for lambda_reg, tau, gamma in product(lambda_reg_values, tau_values, gamma_values):\n",
        "    combination_num += 1\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"COMBINATION {combination_num}/{total_combinations}\")\n",
        "    print(f\"lambda={lambda_reg}, tau={tau}, gamma={gamma}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Initialize biases and latent factors for this combination\n",
        "    user_biases = np.zeros(M)\n",
        "    item_biases = np.zeros(N)\n",
        "    U = (1.0 / np.sqrt(K)) * np.random.randn(M, K)   # User latent factors\n",
        "    V = (1.0 / np.sqrt(K)) * np.random.randn(N, K)   # Item latent factors\n",
        "\n",
        "    # Track metrics for this combination\n",
        "    nll_history = []\n",
        "    rmse_train_history = []\n",
        "    rmse_test_history = []\n",
        "\n",
        "    # ALS training loop\n",
        "    for iter in range(num_iters):\n",
        "\n",
        "        # Update user biases and latent vectors\n",
        "        for m in range(M):\n",
        "            items = data_by_user_train[m]\n",
        "            if not items:\n",
        "                continue\n",
        "\n",
        "            # Update user bias\n",
        "            bias_sum = 0\n",
        "            for movie_id, r in items:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = item_biases[n] + np.dot(U[m], V[n])\n",
        "                residual = r - pred\n",
        "                bias_sum += lambda_reg * residual\n",
        "            user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "\n",
        "            # Update user latent vector\n",
        "            A = np.zeros((K, K))\n",
        "            b = np.zeros(K)\n",
        "\n",
        "            for movie_id, r in items:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                residual = r - user_biases[m] - item_biases[n]\n",
        "\n",
        "                A += lambda_reg * np.outer(V[n], V[n])\n",
        "                b += lambda_reg * residual * V[n]\n",
        "\n",
        "            A += tau * np.eye(K)\n",
        "            U[m] = np.linalg.solve(A, b)\n",
        "\n",
        "        # Update item biases and latent vectors\n",
        "        for n in range(N):\n",
        "            users = data_by_movie_train[n]\n",
        "            if not users:\n",
        "                continue\n",
        "\n",
        "            # Update item bias\n",
        "            bias_sum = 0\n",
        "            for user_id, r in users:\n",
        "                m_idx = data_test.user_id_to_idx[user_id]\n",
        "                pred = user_biases[m_idx] + np.dot(U[m_idx], V[n])\n",
        "                residual = r - pred\n",
        "                bias_sum += lambda_reg * residual\n",
        "            item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "\n",
        "            # Update item latent vector\n",
        "            A = np.zeros((K, K))\n",
        "            b = np.zeros(K)\n",
        "\n",
        "            for user_id, r in users:\n",
        "                m_idx = data_test.user_id_to_idx[user_id]\n",
        "                residual = r - user_biases[m_idx] - item_biases[n]\n",
        "\n",
        "                A += lambda_reg * np.outer(U[m_idx], U[m_idx])\n",
        "                b += lambda_reg * residual * U[m_idx]\n",
        "\n",
        "            A += tau * np.eye(K)\n",
        "            V[n] = np.linalg.solve(A, b)\n",
        "\n",
        "        # Compute negative log likelihood (training)\n",
        "        squared_error = 0\n",
        "        count = 0\n",
        "        for m in range(M):\n",
        "            for movie_id, r in data_by_user_train[m]:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "                squared_error += (r - pred) ** 2\n",
        "                count += 1\n",
        "\n",
        "        # Regularization terms\n",
        "        reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "        reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "        # Log likelihood formula\n",
        "        log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "        nll = -log_likelihood\n",
        "        nll_history.append(nll)\n",
        "\n",
        "        # Training RMSE\n",
        "        rmse_train = np.sqrt(squared_error / count)\n",
        "        rmse_train_history.append(rmse_train)\n",
        "\n",
        "        # Compute test RMSE\n",
        "        squared_error_test = 0\n",
        "        count_test = 0\n",
        "        for m in range(M):\n",
        "            for movie_id, r in data_by_user_test[m]:\n",
        "                n = data_test.movie_id_to_idx[movie_id]\n",
        "                pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "                squared_error_test += (r - pred) ** 2\n",
        "                count_test += 1\n",
        "        rmse_test = np.sqrt(squared_error_test / count_test) if count_test > 0 else float('inf')\n",
        "        rmse_test_history.append(rmse_test)\n",
        "\n",
        "\n",
        "        print(f\"  Iteration {iter+1}/{num_iters}: \"\n",
        "                  f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "                  f\"NLL = {nll:.2f}\")\n",
        "\n",
        "    # Store results for this combination\n",
        "    final_train_rmse = rmse_train_history[-1]\n",
        "    final_test_rmse = rmse_test_history[-1]\n",
        "    final_nll = nll_history[-1]\n",
        "\n",
        "    grid_search_results.append({'lambda_reg': lambda_reg, 'tau': tau, 'gamma': gamma,\n",
        "        'final_train_rmse': final_train_rmse, 'final_test_rmse': final_test_rmse, 'final_nll': final_nll,\n",
        "        'nll_history': nll_history.copy(), 'rmse_train_history': rmse_train_history.copy(), 'rmse_test_history': rmse_test_history.copy()})\n",
        "\n",
        "    print(f\"  FINAL: Train RMSE = {final_train_rmse:.4f}, \"\n",
        "          f\"Test RMSE = {final_test_rmse:.4f}, NLL = {final_nll:.2f}\")\n",
        "\n",
        "# ANALYZE RESULTS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GRID SEARCH RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Lambda':<10} {'Tau':<8} {'Gamma':<10} {'Train RMSE':<12} {'Test RMSE':<12} {'NLL':<12}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for result in grid_search_results:\n",
        "    print(f\"{result['lambda_reg']:<10.4f} {result['tau']:<8.4f} \"\n",
        "          f\"{result['gamma']:<10.4f} {result['final_train_rmse']:<12.4f} \"\n",
        "          f\"{result['final_test_rmse']:<12.4f} {result['final_nll']:<12.2f}\")\n",
        "\n",
        "# Find best based on test RMSE\n",
        "best_result = min(grid_search_results, key=lambda x: x['final_test_rmse'])\n",
        "\n",
        "# Also find best based on NLL (for reference)\n",
        "best_nll_result = min(grid_search_results, key=lambda x: x['final_nll'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEST HYPERPARAMETERS (Based on Test RMSE)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"lambda_reg: {best_result['lambda_reg']}\")\n",
        "print(f\"tau: {best_result['tau']}\")\n",
        "print(f\"gamma: {best_result['gamma']}\")\n",
        "print(f\"Final Train RMSE: {best_result['final_train_rmse']:.4f}\")\n",
        "print(f\"Final Test RMSE: {best_result['final_test_rmse']:.4f}\")\n",
        "print(f\"Final NLL: {best_result['final_nll']:.2f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if best_nll_result != best_result:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BEST HYPERPARAMETERS (Based on NLL)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"lambda_reg: {best_nll_result['lambda_reg']}\")\n",
        "    print(f\"tau: {best_nll_result['tau']}\")\n",
        "    print(f\"gamma: {best_nll_result['gamma']}\")\n",
        "    print(f\"Final Train RMSE: {best_nll_result['final_train_rmse']:.4f}\")\n",
        "    print(f\"Final Test RMSE: {best_nll_result['final_test_rmse']:.4f}\")\n",
        "    print(f\"Final NLL: {best_nll_result['final_nll']:.2f}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# VISUALIZATION: TOP 5 CONFIGURATIONS\n",
        "\n",
        "# Sort by test RMSE and get top 5\n",
        "top_5_results = sorted(grid_search_results, key=lambda x: x['final_test_rmse'])[:5]\n",
        "\n",
        "fig, axes = plt.subplots(3, 5, figsize=(25, 12))\n",
        "\n",
        "for idx, result in enumerate(top_5_results):\n",
        "    # Plot NLL\n",
        "    axes[0, idx].plot(result['nll_history'], marker='o', color='purple', linewidth=2)\n",
        "    axes[0, idx].set_title(f\"Rank {idx+1}: NLL\\nλ={result['lambda_reg']:.4f}, \"\n",
        "                           f\"τ={result['tau']:.4f}, γ={result['gamma']:.4f}\", fontsize=9)\n",
        "    axes[0, idx].set_xlabel(\"Iteration\")\n",
        "    axes[0, idx].set_ylabel(\"NLL\")\n",
        "    axes[0, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot Training RMSE\n",
        "    axes[1, idx].plot(result['rmse_train_history'], marker='o', color='orange', linewidth=2)\n",
        "    axes[1, idx].set_title(f\"Train RMSE: {result['final_train_rmse']:.4f}\", fontsize=10)\n",
        "    axes[1, idx].set_xlabel(\"Iteration\")\n",
        "    axes[1, idx].set_ylabel(\"RMSE\")\n",
        "    axes[1, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot Test RMSE\n",
        "    axes[2, idx].plot(result['rmse_test_history'], marker='o', color='green', linewidth=2)\n",
        "    axes[2, idx].set_title(f\"Test RMSE: {result['final_test_rmse']:.4f}\", fontsize=10, fontweight='bold')\n",
        "    axes[2, idx].set_xlabel(\"Iteration\")\n",
        "    axes[2, idx].set_ylabel(\"RMSE\")\n",
        "    axes[2, idx].grid(True, alpha=0.3)\n",
        "\n",
        "    # Highlight best configuration with red border\n",
        "    if result == best_result:\n",
        "        for ax in axes[:, idx]:\n",
        "            for spine in ax.spines.values():\n",
        "                spine.set_edgecolor('red')\n",
        "                spine.set_linewidth(3)\n",
        "\n",
        "plt.suptitle(\"Top 5 Hyperparameter Configurations (Ranked by Test RMSE)\",\n",
        "             fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Best Hyperparameters (from grid search with K={K})\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\"\"\n",
        "K = {K}\n",
        "num_iters = 10\n",
        "lambda_reg = {best_result['lambda_reg']}\n",
        "tau = {best_result['tau']}\n",
        "gamma = {best_result['gamma']}\n",
        "\n",
        "\"\"\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ_Y4kUJZTER"
      },
      "source": [
        "## Practical 4:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4omeojicsUZ"
      },
      "source": [
        "### Train/Test Split Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Zfn4MAanu_"
      },
      "source": [
        "#### Approach\n",
        "We implemented an efficient **90/10 random split** of the MovieLens dataset with optimized data structures for fast access during training.\n",
        "\n",
        "#### Key Design Decisions\n",
        "\n",
        "1. **Dual-Index Structure**\n",
        "   - Created **both** user-indexed and movie-indexed versions of train/test data\n",
        "   - Enables O(1) lookup time for both user-based and movie-based queries\n",
        "   - Critical for ALS algorithm which alternates between updating users and movies\n",
        "\n",
        "2. **Memory Optimization**\n",
        "   - Pre-sorted arrays by user_idx and movie_idx\n",
        "   - Built cumulative index arrays (`user_train_start`, `movie_train_start`, `user_test_start`, `movie_test_start`)\n",
        "   - Allows direct slicing to retrieve all ratings for any user/movie without search\n",
        "   - Example: `train_ratings_by_user[user_train_start[m]:user_train_start[m+1]]` gives all training ratings for user `m`\n",
        "   - **Memory cleanup**: Deleted original unsplit data structures and ran garbage collection to free ~1GB+ of memory\n",
        "\n",
        "3. **Performance Benefits**\n",
        "   - **Before**: Iterating through all ratings to find user's movies: O(total_ratings)\n",
        "   - **After**: Direct array slicing with index lookup: O(1) access + O(k) retrieval where k = number of user's ratings\n",
        "   - Crucial for large datasets (25M+ ratings) where naive lookups would be prohibitively slow\n",
        "\n",
        "#### Data Structure Summary\n",
        "```python\n",
        "# Training set\n",
        "train_ratings_by_user   # Sorted by user_idx: [user_idx, movie_idx, rating]\n",
        "train_ratings_by_movie  # Sorted by movie_idx: [user_idx, movie_idx, rating]\n",
        "user_train_start        # Index array for O(1) user lookup\n",
        "movie_train_start       # Index array for O(1) movie lookup\n",
        "\n",
        "# Test set (same structure)\n",
        "test_ratings_by_user    # Sorted by user_idx: [user_idx, movie_idx, rating]\n",
        "test_ratings_by_movie   # Sorted by movie_idx: [user_idx, movie_idx, rating]\n",
        "user_test_start         # Index array for O(1) user lookup\n",
        "movie_test_start        # Index array for O(1) movie lookup\n",
        "```\n",
        "\n",
        "This architecture enables efficient alternating least squares updates by providing fast access to both \"all movies rated by user m\" and \"all users who rated movie n\" for both training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1ipsWyVcC4d",
        "outputId": "578ccb33-1cf4-484d-f13b-cd8e8e6a7ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CONVERTING TO NUMPY ARRAYS\n",
            "======================================================================\n",
            "Total ratings: 32,000,204\n",
            "Creating rating arrays...\n",
            "  Processing user 10,000/200,948...\n",
            "  Processing user 20,000/200,948...\n",
            "  Processing user 30,000/200,948...\n",
            "  Processing user 40,000/200,948...\n",
            "  Processing user 50,000/200,948...\n",
            "  Processing user 60,000/200,948...\n",
            "  Processing user 70,000/200,948...\n",
            "  Processing user 80,000/200,948...\n",
            "  Processing user 90,000/200,948...\n",
            "  Processing user 100,000/200,948...\n",
            "  Processing user 110,000/200,948...\n",
            "  Processing user 120,000/200,948...\n",
            "  Processing user 130,000/200,948...\n",
            "  Processing user 140,000/200,948...\n",
            "  Processing user 150,000/200,948...\n",
            "  Processing user 160,000/200,948...\n",
            "  Processing user 170,000/200,948...\n",
            "  Processing user 180,000/200,948...\n",
            "  Processing user 190,000/200,948...\n",
            "  Processing user 200,000/200,948...\n",
            "✓ Array created: 366.2 MB\n",
            "\n",
            "Generating train/test split (90/10)...\n",
            "✓ Train ratings: 28,802,949 (90.0%)\n",
            "✓ Test ratings: 3,197,255 (10.0%)\n",
            "  Train array: 329.6 MB\n",
            "  Test array: 36.6 MB\n",
            "\n",
            "======================================================================\n",
            "BUILDING FAST ACCESS INDICES\n",
            "======================================================================\n",
            "Sorting by user...\n",
            "Sorting by movie...\n",
            "Building lookup indices...\n",
            "  Indexing users (train)...\n",
            "  Indexing users (test)...\n",
            "  Indexing movies (train)...\n",
            "  Indexing movies (test)...\n",
            "✓ Indexing complete!\n",
            "\n",
            "Cleaning up...\n",
            "✓ Memory freed!\n",
            "\n",
            "======================================================================\n",
            "Ready for training with 200,948 users and 84,432 movies\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# CONVERT TO NUMPY ARRAYS & TRAIN/TEST SPLIT\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONVERTING TO NUMPY ARRAYS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "n_users = data.num_users()\n",
        "n_movies = data.num_movies()\n",
        "\n",
        "# Count total ratings\n",
        "total_ratings = sum(len(ratings) for ratings in data.data_by_user)\n",
        "print(f\"Total ratings: {total_ratings:,}\")\n",
        "\n",
        "# Pre-allocate array: [user_idx, movie_idx, rating]\n",
        "print(\"Creating rating arrays...\")\n",
        "all_ratings = np.zeros((total_ratings, 3), dtype=np.float32)\n",
        "\n",
        "# Fill the array\n",
        "idx = 0\n",
        "for user_idx in range(n_users):\n",
        "    if user_idx % 10000 == 0 and user_idx > 0:\n",
        "        print(f\"  Processing user {user_idx:,}/{n_users:,}...\")\n",
        "\n",
        "    ratings = data.data_by_user[user_idx]\n",
        "    for movie_id, rating in ratings:\n",
        "        movie_idx = data.movie_id_to_idx[movie_id]\n",
        "        all_ratings[idx] = [user_idx, movie_idx, rating]\n",
        "        idx += 1\n",
        "\n",
        "print(f\"✓ Array created: {all_ratings.nbytes / 1024**2:.1f} MB\")\n",
        "\n",
        "# TRAIN/TEST SPLIT (90/10)\n",
        "\n",
        "print(\"\\nGenerating train/test split (90/10)...\")\n",
        "np.random.seed(42)\n",
        "is_train = np.random.rand(total_ratings) < 0.9\n",
        "\n",
        "# Split into train and test\n",
        "train_ratings = all_ratings[is_train]\n",
        "test_ratings = all_ratings[~is_train]\n",
        "\n",
        "print(f\"✓ Train ratings: {len(train_ratings):,} ({len(train_ratings)/total_ratings*100:.1f}%)\")\n",
        "print(f\"✓ Test ratings: {len(test_ratings):,} ({len(test_ratings)/total_ratings*100:.1f}%)\")\n",
        "print(f\"  Train array: {train_ratings.nbytes / 1024**2:.1f} MB\")\n",
        "print(f\"  Test array: {test_ratings.nbytes / 1024**2:.1f} MB\")\n",
        "\n",
        "# SORT AND BUILD FAST ACCESS INDICES\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BUILDING FAST ACCESS INDICES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Sort by user for user-based access\n",
        "print(\"Sorting by user...\")\n",
        "train_ratings_by_user = train_ratings[train_ratings[:, 0].argsort()]\n",
        "test_ratings_by_user = test_ratings[test_ratings[:, 0].argsort()]\n",
        "\n",
        "# Sort by movie for movie-based access\n",
        "print(\"Sorting by movie...\")\n",
        "train_ratings_by_movie = train_ratings[train_ratings[:, 1].argsort()]\n",
        "test_ratings_by_movie = test_ratings[test_ratings[:, 1].argsort()]\n",
        "\n",
        "# Build index arrays for O(1) lookup\n",
        "print(\"Building lookup indices...\")\n",
        "user_train_start = np.zeros(n_users + 1, dtype=np.int32)\n",
        "user_test_start = np.zeros(n_users + 1, dtype=np.int32)\n",
        "movie_train_start = np.zeros(n_movies + 1, dtype=np.int32)\n",
        "movie_test_start = np.zeros(n_movies + 1, dtype=np.int32)\n",
        "\n",
        "# Build user indices (train)\n",
        "print(\"  Indexing users (train)...\")\n",
        "current_user = -1\n",
        "for i in range(len(train_ratings_by_user)):\n",
        "    user = int(train_ratings_by_user[i, 0])\n",
        "    if user != current_user:\n",
        "        for u in range(current_user + 1, user + 1):\n",
        "            user_train_start[u] = i\n",
        "        current_user = user\n",
        "for u in range(current_user + 1, n_users + 1):\n",
        "    user_train_start[u] = len(train_ratings_by_user)\n",
        "\n",
        "# Build user indices (test)\n",
        "print(\"  Indexing users (test)...\")\n",
        "current_user = -1\n",
        "for i in range(len(test_ratings_by_user)):\n",
        "    user = int(test_ratings_by_user[i, 0])\n",
        "    if user != current_user:\n",
        "        for u in range(current_user + 1, user + 1):\n",
        "            user_test_start[u] = i\n",
        "        current_user = user\n",
        "for u in range(current_user + 1, n_users + 1):\n",
        "    user_test_start[u] = len(test_ratings_by_user)\n",
        "\n",
        "# Build movie indices (train)\n",
        "print(\"  Indexing movies (train)...\")\n",
        "current_movie = -1\n",
        "for i in range(len(train_ratings_by_movie)):\n",
        "    movie = int(train_ratings_by_movie[i, 1])\n",
        "    if movie != current_movie:\n",
        "        for m in range(current_movie + 1, movie + 1):\n",
        "            movie_train_start[m] = i\n",
        "        current_movie = movie\n",
        "for m in range(current_movie + 1, n_movies + 1):\n",
        "    movie_train_start[m] = len(train_ratings_by_movie)\n",
        "\n",
        "# Build movie indices (test)\n",
        "print(\"  Indexing movies (test)...\")\n",
        "current_movie = -1\n",
        "for i in range(len(test_ratings_by_movie)):\n",
        "    movie = int(test_ratings_by_movie[i, 1])\n",
        "    if movie != current_movie:\n",
        "        for m in range(current_movie + 1, movie + 1):\n",
        "            movie_test_start[m] = i\n",
        "        current_movie = movie\n",
        "for m in range(current_movie + 1, n_movies + 1):\n",
        "    movie_test_start[m] = len(test_ratings_by_movie)\n",
        "\n",
        "print(\"✓ Indexing complete!\")\n",
        "\n",
        "# FREE MEMORY\n",
        "\n",
        "print(\"\\nCleaning up...\")\n",
        "del all_ratings, train_ratings, test_ratings\n",
        "del data.data_by_user, data.data_by_movie\n",
        "gc.collect()\n",
        "\n",
        "print(\"✓ Memory freed!\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Ready for training with {n_users:,} users and {n_movies:,} movies\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0-VjqNDsgEZe"
      },
      "outputs": [],
      "source": [
        "# HELPER FUNCTIONS FOR FAST DATA ACCESS\n",
        "\n",
        "def get_user_train_ratings(user_idx):\n",
        "    \"\"\"Get all training ratings for a specific user as [movie_idx, rating]\"\"\"\n",
        "    start = user_train_start[user_idx]\n",
        "    end = user_train_start[user_idx + 1]\n",
        "    # Return columns 1 (movie_idx) and 2 (rating)\n",
        "    return train_ratings_by_user[start:end, 1:3]\n",
        "\n",
        "def get_user_test_ratings(user_idx):\n",
        "    \"\"\"Get all test ratings for a specific user as [movie_idx, rating]\"\"\"\n",
        "    start = user_test_start[user_idx]\n",
        "    end = user_test_start[user_idx + 1]\n",
        "    # Return columns 1 (movie_idx) and 2 (rating)\n",
        "    return test_ratings_by_user[start:end, 1:3]\n",
        "\n",
        "def get_movie_train_ratings(movie_idx):\n",
        "    \"\"\"Get all training ratings for a specific movie as [user_idx, rating]\"\"\"\n",
        "    start = movie_train_start[movie_idx]\n",
        "    end = movie_train_start[movie_idx + 1]\n",
        "    # Return columns 0 (user_idx) and 2 (rating)\n",
        "    return train_ratings_by_movie[start:end, [0, 2]]\n",
        "\n",
        "def get_movie_test_ratings(movie_idx):\n",
        "    \"\"\"Get all test ratings for a specific movie as [user_idx, rating]\"\"\"\n",
        "    start = movie_test_start[movie_idx]\n",
        "    end = movie_test_start[movie_idx + 1]\n",
        "    # Return columns 0 (user_idx) and 2 (rating)\n",
        "    return test_ratings_by_movie[start:end, [0, 2]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLGaUfHWgFj2"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VkxxmfxczXn"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "\n",
        "K = 32               # Number of latent factors\n",
        "num_iters = 40       # Number of ALS iterations\n",
        "lambda_reg = 0.001   # Regularization for latent factors (U, V)\n",
        "tau = 0.05           # Regularization term for user/item vectors\n",
        "gamma = 0.001        # Regularization for biases\n",
        "\n",
        "M = n_users          # Number of users\n",
        "N = n_movies         # Number of movies\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING ALS MODEL\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Users: {M:,}\")\n",
        "print(f\"Movies: {N:,}\")\n",
        "print(f\"Latent factors (K): {K}\")\n",
        "print(f\"Iterations: {num_iters}\")\n",
        "print(f\"λ (lambda_reg): {lambda_reg}\")\n",
        "print(f\"τ (tau): {tau}\")\n",
        "print(f\"γ (gamma): {gamma}\")\n",
        "\n",
        "# INITIALIZE BIASES AND LATENT FACTORS\n",
        "\n",
        "user_biases = np.zeros(M, dtype=np.float32)\n",
        "item_biases = np.zeros(N, dtype=np.float32)\n",
        "U = ((1/math.sqrt(K)) * np.random.randn(M, K)).astype(np.float32)   # User latent factors\n",
        "V = ((1/math.sqrt(K)) * np.random.randn(N, K)).astype(np.float32)   # Item latent factors\n",
        "\n",
        "# For plotting\n",
        "nll_history = []\n",
        "rmse_train_history = []\n",
        "rmse_test_history = []\n",
        "\n",
        "# ALS TRAINING LOOP\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for iter in range(num_iters):\n",
        "\n",
        "    # UPDATE USER BIASES AND LATENT VECTORS\n",
        "    for m in range(M):\n",
        "        items = get_user_train_ratings(m)\n",
        "        if len(items) == 0: # if user has no ratings\n",
        "            continue\n",
        "\n",
        "        # Update user bias\n",
        "        bias_sum = 0\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            pred = item_biases[n] + np.dot(U[m], V[n])\n",
        "            residual = r - pred\n",
        "            bias_sum += lambda_reg * residual\n",
        "        user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "\n",
        "        # Update user latent vector\n",
        "        A = np.zeros((K, K), dtype=np.float32)\n",
        "        b = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            residual = r - user_biases[m] - item_biases[n]\n",
        "\n",
        "            A += lambda_reg * np.outer(V[n], V[n])\n",
        "            b += lambda_reg * residual * V[n]\n",
        "\n",
        "        A += tau * np.eye(K, dtype=np.float32)\n",
        "        U[m] = np.linalg.solve(A, b)\n",
        "\n",
        "    # UPDATE ITEM BIASES AND LATENT VECTORS\n",
        "    for n in range(N):\n",
        "        users = get_movie_train_ratings(n)\n",
        "        if len(users) == 0:\n",
        "            continue\n",
        "\n",
        "        # Update item bias\n",
        "        bias_sum = 0\n",
        "        for i in range(len(users)):\n",
        "            m_idx = int(users[i, 0])  # user_idx\n",
        "            r = users[i, 1]            # rating\n",
        "            pred = user_biases[m_idx] + np.dot(U[m_idx], V[n])\n",
        "            residual = r - pred\n",
        "            bias_sum += lambda_reg * residual\n",
        "        item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "\n",
        "        # Update item latent vector\n",
        "        A = np.zeros((K, K), dtype=np.float32)\n",
        "        b = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "        for i in range(len(users)):\n",
        "            m_idx = int(users[i, 0])  # user_idx\n",
        "            r = users[i, 1]            # rating\n",
        "            residual = r - user_biases[m_idx] - item_biases[n]\n",
        "\n",
        "            A += lambda_reg * np.outer(U[m_idx], U[m_idx])\n",
        "            b += lambda_reg * residual * U[m_idx]\n",
        "\n",
        "        A += tau * np.eye(K, dtype=np.float32)\n",
        "        V[n] = np.linalg.solve(A, b)\n",
        "\n",
        "    # COMPUTE NEGATIVE LOG LIKELIHOOD (TRAINING)\n",
        "    squared_error = 0\n",
        "    count = 0\n",
        "\n",
        "    for m in range(M):\n",
        "        items = get_user_train_ratings(m)\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error += (r - pred) ** 2\n",
        "            count += 1\n",
        "\n",
        "    # Regularization terms\n",
        "    reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "    reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "    # Log likelihood formula from slides\n",
        "    log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "\n",
        "    # Negative log likelihood (negate to get NLL)\n",
        "    nll = -log_likelihood\n",
        "    nll_history.append(nll)\n",
        "\n",
        "    # Training RMSE\n",
        "    rmse_train = np.sqrt(squared_error / count)\n",
        "    rmse_train_history.append(rmse_train)\n",
        "\n",
        "    # COMPUTE TEST RMSE\n",
        "    squared_error_test = 0\n",
        "    count_test = 0\n",
        "\n",
        "    for m in range(M):\n",
        "        items = get_user_test_ratings(m)\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error_test += (r - pred) ** 2\n",
        "            count_test += 1\n",
        "\n",
        "    rmse_test = np.sqrt(squared_error_test / count_test) if count_test > 0 else 0\n",
        "    rmse_test_history.append(rmse_test)\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_iters}: \"\n",
        "          f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "          f\"NLL = {nll:.2f}\")\n",
        "\n",
        "# PLOT RESULTS\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(nll_history, marker='o', color='purple')\n",
        "plt.title(\"Negative Log Likelihood (Training)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Negative Log Likelihood\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(rmse_train_history, marker='o', color='orange')\n",
        "plt.title(\"Training RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(rmse_test_history, marker='o', color='green')\n",
        "plt.title(\"Test RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Final Train RMSE: {rmse_train_history[-1]:.4f}\")\n",
        "print(f\"Final Test RMSE: {rmse_test_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaqFDlYihdLY"
      },
      "source": [
        "### Trying to vectorise training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG9QVh1shgov"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS\n",
        "\n",
        "K = 32               # Number of latent factors\n",
        "num_iters = 15       # Number of ALS iterations\n",
        "lambda_reg = 0.001   # Regularization for latent factors (U, V)\n",
        "tau = 0.05           # Regularization term for user/item vectors\n",
        "gamma = 0.001        # Regularization for biases\n",
        "\n",
        "\n",
        "M = n_users          # Number of users\n",
        "N = n_movies         # Number of movies\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING ALS MODEL\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Users: {M:,}\")\n",
        "print(f\"Movies: {N:,}\")\n",
        "print(f\"Latent factors (K): {K}\")\n",
        "print(f\"Iterations: {num_iters}\")\n",
        "print(f\"λ (lambda_reg): {lambda_reg}\")\n",
        "print(f\"τ (tau): {tau}\")\n",
        "print(f\"γ (gamma): {gamma}\")\n",
        "\n",
        "# INITIALIZE BIASES AND LATENT FACTORS\n",
        "\n",
        "user_biases = np.zeros(M, dtype=np.float32)\n",
        "item_biases = np.zeros(N, dtype=np.float32)\n",
        "U = ((1/math.sqrt(K)) * np.random.randn(M, K)).astype(np.float32)   # User latent factors\n",
        "V = ((1/math.sqrt(K)) * np.random.randn(N, K)).astype(np.float32)   # Item latent factors\n",
        "\n",
        "# For plotting\n",
        "nll_history = []\n",
        "rmse_train_history = []\n",
        "rmse_test_history = []\n",
        "\n",
        "# ALS TRAINING LOOP\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for iter in range(num_iters):\n",
        "\n",
        "    # UPDATE USER BIASES AND LATENT VECTORS\n",
        "    for m in range(M):\n",
        "        items = get_user_train_ratings(m)\n",
        "        if len(items) == 0: # if user has no ratings\n",
        "            continue\n",
        "\n",
        "        # Updated user bias\n",
        "        movie_indices = items[:, 0].astype(np.int32)  # All movie indices for this user\n",
        "        ratings = items[:, 1]  # All ratings\n",
        "        # Vectorized prediction: item_biases[n] + U[m] @ V[n] for all n\n",
        "        predictions = item_biases[movie_indices] + (U[m] @ V[movie_indices].T)\n",
        "        residuals = ratings - predictions\n",
        "        bias_sum = lambda_reg * np.sum(residuals)\n",
        "        user_biases[m] = bias_sum / (lambda_reg * len(items) + gamma)\n",
        "\n",
        "        # Update user latent vector\n",
        "        movie_indices = items[:, 0].astype(np.int32)\n",
        "        ratings = items[:, 1]\n",
        "        V_subset = V[movie_indices]  # Shape: (num_items, K)\n",
        "        residuals = ratings - user_biases[m] - item_biases[movie_indices]  # Shape: (num_items,)\n",
        "\n",
        "        # Vectorized computation: A = λ Σ V[n] V[n]^T = λ V_subset^T @ V_subset\n",
        "        A = lambda_reg * (V_subset.T @ V_subset) + tau * np.eye(K, dtype=np.float32)\n",
        "        # Vectorized computation: b = λ Σ residual[n] * V[n] = λ V_subset^T @ residuals\n",
        "        b = lambda_reg * (V_subset.T @ residuals)\n",
        "\n",
        "        U[m] = np.linalg.solve(A, b)\n",
        "\n",
        "    # UPDATE ITEM BIASES AND LATENT VECTORS\n",
        "    for n in range(N):\n",
        "        users = get_movie_train_ratings(n)\n",
        "        if len(users) == 0:\n",
        "            continue\n",
        "\n",
        "        # Update item bias\n",
        "        user_indices = users[:, 0].astype(np.int32)  # All user indices for this movie\n",
        "        ratings = users[:, 1]  # All ratings\n",
        "        # Vectorized prediction: user_biases[m] + U[m] @ V[n] for all m\n",
        "        predictions = user_biases[user_indices] + (U[user_indices] @ V[n])\n",
        "        residuals = ratings - predictions\n",
        "        bias_sum = lambda_reg * np.sum(residuals)\n",
        "        item_biases[n] = bias_sum / (lambda_reg * len(users) + gamma)\n",
        "\n",
        "        # Update item latent vector\n",
        "        user_indices = users[:, 0].astype(np.int32)\n",
        "        ratings = users[:, 1]\n",
        "        U_subset = U[user_indices]  # Shape: (num_users, K)\n",
        "        residuals = ratings - user_biases[user_indices] - item_biases[n]  # Shape: (num_users,)\n",
        "\n",
        "        # Vectorized computation: A = λ Σ U[m] U[m]^T = λ U_subset^T @ U_subset\n",
        "        A = lambda_reg * (U_subset.T @ U_subset) + tau * np.eye(K, dtype=np.float32)\n",
        "        # Vectorized computation: b = λ Σ residual[m] * U[m] = λ U_subset^T @ residuals\n",
        "        b = lambda_reg * (U_subset.T @ residuals)\n",
        "\n",
        "        V[n] = np.linalg.solve(A, b)\n",
        "\n",
        "    # COMPUTE NEGATIVE LOG LIKELIHOOD (TRAINING)\n",
        "    squared_error = 0\n",
        "    count = 0\n",
        "\n",
        "    for m in range(M):\n",
        "        items = get_user_train_ratings(m)\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error += (r - pred) ** 2\n",
        "            count += 1\n",
        "\n",
        "    # Regularization terms\n",
        "    reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "    reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "    # Log likelihood formula from slides\n",
        "    log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "\n",
        "    # Negative log likelihood (negate to get NLL)\n",
        "    nll = -log_likelihood\n",
        "    nll_history.append(nll)\n",
        "\n",
        "    # Training RMSE\n",
        "    rmse_train = np.sqrt(squared_error / count)\n",
        "    rmse_train_history.append(rmse_train)\n",
        "\n",
        "    # COMPUTE TEST RMSE\n",
        "    squared_error_test = 0\n",
        "    count_test = 0\n",
        "\n",
        "    for m in range(M):\n",
        "        items = get_user_test_ratings(m)\n",
        "        for i in range(len(items)):\n",
        "            n = int(items[i, 0])  # movie_idx\n",
        "            r = items[i, 1]        # rating\n",
        "            pred = user_biases[m] + item_biases[n] + np.dot(U[m], V[n])\n",
        "            squared_error_test += (r - pred) ** 2\n",
        "            count_test += 1\n",
        "\n",
        "    rmse_test = np.sqrt(squared_error_test / count_test) if count_test > 0 else 0\n",
        "    rmse_test_history.append(rmse_test)\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_iters}: \"\n",
        "          f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "          f\"NLL = {nll:.2f}\")\n",
        "\n",
        "# PLOT RESULTS\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(nll_history, marker='o', color='purple')\n",
        "plt.title(\"Negative Log Likelihood (Training)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Negative Log Likelihood\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(rmse_train_history, marker='o', color='orange')\n",
        "plt.title(\"Training RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(rmse_test_history, marker='o', color='green')\n",
        "plt.title(\"Test RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Final Train RMSE: {rmse_train_history[-1]:.4f}\")\n",
        "print(f\"Final Test RMSE: {rmse_test_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgnFMSUloC-E"
      },
      "source": [
        "### optimising with numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading uv 0.9.21 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /home/hassanh/.local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n"
          ]
        }
      ],
      "source": [
        "!curl -LsSf https://astral.sh/uv/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nZ7aABYcoKSx"
      },
      "outputs": [],
      "source": [
        "from numba import njit, prange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AkyBpv0DoGrT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# CELL 2: Numba helper functions\n",
        "# (Add this cell BEFORE the \"Trying to vectorise training\" cell)\n",
        "# =============================================================================\n",
        "\n",
        "@njit\n",
        "def cholesky_solve(A, b, K):\n",
        "    \"\"\"\n",
        "    Solve Ax = b using Cholesky decomposition (A must be symmetric positive definite).\n",
        "    This is 2x faster than general LU decomposition for SPD matrices.\n",
        "    \"\"\"\n",
        "    # Cholesky decomposition: A = L @ L.T\n",
        "    L = np.zeros((K, K), dtype=np.float32)\n",
        "\n",
        "    for i in range(K):\n",
        "        for j in range(i + 1):\n",
        "            s = 0.0\n",
        "            for k in range(j):\n",
        "                s += L[i, k] * L[j, k]\n",
        "\n",
        "            if i == j:\n",
        "                val = A[i, i] - s\n",
        "                if val > 0:\n",
        "                    L[i, j] = np.sqrt(val)\n",
        "                else:\n",
        "                    L[i, j] = 1e-6  # Numerical stability\n",
        "            else:\n",
        "                if L[j, j] > 0:\n",
        "                    L[i, j] = (A[i, j] - s) / L[j, j]\n",
        "                else:\n",
        "                    L[i, j] = 0.0\n",
        "\n",
        "    # Forward substitution: L @ y = b\n",
        "    y = np.zeros(K, dtype=np.float32)\n",
        "    for i in range(K):\n",
        "        s = 0.0\n",
        "        for j in range(i):\n",
        "            s += L[i, j] * y[j]\n",
        "        if L[i, i] > 0:\n",
        "            y[i] = (b[i] - s) / L[i, i]\n",
        "        else:\n",
        "            y[i] = 0.0\n",
        "\n",
        "    # Backward substitution: L.T @ x = y\n",
        "    x = np.zeros(K, dtype=np.float32)\n",
        "    for i in range(K - 1, -1, -1):\n",
        "        s = 0.0\n",
        "        for j in range(i + 1, K):\n",
        "            s += L[j, i] * x[j]  # L.T[i, j] = L[j, i]\n",
        "        if L[i, i] > 0:\n",
        "            x[i] = (y[i] - s) / L[i, i]\n",
        "        else:\n",
        "            x[i] = 0.0\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def update_all_users_numba(\n",
        "    M, K, lambda_reg, tau, gamma,\n",
        "    user_biases, item_biases, U, V,\n",
        "    train_ratings_by_user,\n",
        "    user_train_start\n",
        "):\n",
        "    \"\"\"Update all user biases and latent factors in parallel.\"\"\"\n",
        "    for m in prange(M):\n",
        "        start = user_train_start[m]\n",
        "        end = user_train_start[m + 1]\n",
        "        count = end - start\n",
        "\n",
        "        if count == 0:\n",
        "            continue\n",
        "\n",
        "        # Update user bias\n",
        "        bias_sum = 0.0\n",
        "        for idx in range(start, end):\n",
        "            n = np.int32(train_ratings_by_user[idx, 1])\n",
        "            r = train_ratings_by_user[idx, 2]\n",
        "            pred = item_biases[n]\n",
        "            for k in range(K):\n",
        "                pred += U[m, k] * V[n, k]\n",
        "            bias_sum += lambda_reg * (r - pred)\n",
        "\n",
        "        user_biases[m] = bias_sum / (lambda_reg * count + gamma)\n",
        "\n",
        "        # Update user latent vector\n",
        "        A = np.zeros((K, K), dtype=np.float32)\n",
        "        b = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "        for idx in range(start, end):\n",
        "            n = np.int32(train_ratings_by_user[idx, 1])\n",
        "            r = train_ratings_by_user[idx, 2]\n",
        "            residual = r - user_biases[m] - item_biases[n]\n",
        "\n",
        "            for j in range(K):\n",
        "                b[j] += lambda_reg * residual * V[n, j]\n",
        "                for k in range(K):\n",
        "                    A[j, k] += lambda_reg * V[n, j] * V[n, k]\n",
        "\n",
        "        for j in range(K):\n",
        "            A[j, j] += tau\n",
        "\n",
        "        U[m] = cholesky_solve(A, b, K)\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def update_all_items_numba(\n",
        "    N, K, lambda_reg, tau, gamma,\n",
        "    user_biases, item_biases, U, V,\n",
        "    train_ratings_by_movie,\n",
        "    movie_train_start\n",
        "):\n",
        "    \"\"\"Update all item biases and latent factors in parallel.\"\"\"\n",
        "    for n in prange(N):\n",
        "        start = movie_train_start[n]\n",
        "        end = movie_train_start[n + 1]\n",
        "        count = end - start\n",
        "\n",
        "        if count == 0:\n",
        "            continue\n",
        "\n",
        "        # Update item bias\n",
        "        bias_sum = 0.0\n",
        "        for idx in range(start, end):\n",
        "            m = np.int32(train_ratings_by_movie[idx, 0])\n",
        "            r = train_ratings_by_movie[idx, 2]\n",
        "            pred = user_biases[m]\n",
        "            for k in range(K):\n",
        "                pred += U[m, k] * V[n, k]\n",
        "            bias_sum += lambda_reg * (r - pred)\n",
        "\n",
        "        item_biases[n] = bias_sum / (lambda_reg * count + gamma)\n",
        "\n",
        "        # Update item latent vector\n",
        "        A = np.zeros((K, K), dtype=np.float32)\n",
        "        b = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "        for idx in range(start, end):\n",
        "            m = np.int32(train_ratings_by_movie[idx, 0])\n",
        "            r = train_ratings_by_movie[idx, 2]\n",
        "            residual = r - user_biases[m] - item_biases[n]\n",
        "\n",
        "            for j in range(K):\n",
        "                b[j] += lambda_reg * residual * U[m, j]\n",
        "                for k in range(K):\n",
        "                    A[j, k] += lambda_reg * U[m, j] * U[m, k]\n",
        "\n",
        "        for j in range(K):\n",
        "            A[j, j] += tau\n",
        "\n",
        "        V[n] = cholesky_solve(A, b, K)\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def compute_train_metrics_numba(\n",
        "    M, K,\n",
        "    user_biases, item_biases, U, V,\n",
        "    train_ratings_by_user,\n",
        "    user_train_start\n",
        "):\n",
        "    \"\"\"Compute training squared error and count in parallel.\"\"\"\n",
        "    squared_error = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for m in prange(M):\n",
        "        start = user_train_start[m]\n",
        "        end = user_train_start[m + 1]\n",
        "\n",
        "        local_error = 0.0\n",
        "        local_count = 0\n",
        "\n",
        "        for idx in range(start, end):\n",
        "            n = np.int32(train_ratings_by_user[idx, 1])\n",
        "            r = train_ratings_by_user[idx, 2]\n",
        "\n",
        "            pred = user_biases[m] + item_biases[n]\n",
        "            for k in range(K):\n",
        "                pred += U[m, k] * V[n, k]\n",
        "\n",
        "            local_error += (r - pred) ** 2\n",
        "            local_count += 1\n",
        "\n",
        "        squared_error += local_error\n",
        "        count += local_count\n",
        "\n",
        "    return squared_error, count\n",
        "\n",
        "\n",
        "@njit(parallel=True)\n",
        "def compute_test_rmse_numba(\n",
        "    M, K,\n",
        "    user_biases, item_biases, U, V,\n",
        "    test_ratings_by_user,\n",
        "    user_test_start\n",
        "):\n",
        "    \"\"\"Compute test squared error and count in parallel.\"\"\"\n",
        "    squared_error = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for m in prange(M):\n",
        "        start = user_test_start[m]\n",
        "        end = user_test_start[m + 1]\n",
        "\n",
        "        local_error = 0.0\n",
        "        local_count = 0\n",
        "\n",
        "        for idx in range(start, end):\n",
        "            n = np.int32(test_ratings_by_user[idx, 1])\n",
        "            r = test_ratings_by_user[idx, 2]\n",
        "\n",
        "            pred = user_biases[m] + item_biases[n]\n",
        "            for k in range(K):\n",
        "                pred += U[m, k] * V[n, k]\n",
        "\n",
        "            local_error += (r - pred) ** 2\n",
        "            local_count += 1\n",
        "\n",
        "        squared_error += local_error\n",
        "        count += local_count\n",
        "\n",
        "    return squared_error, count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "4WLeuTrjoRRV",
        "outputId": "cf1a6daa-c5a3-4530-e32a-a41a70748c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "INITIALIZING ALS MODEL (NUMBA OPTIMIZED)\n",
            "======================================================================\n",
            "Users: 200,948\n",
            "Movies: 84,432\n",
            "Latent factors (K): 32\n",
            "Iterations: 15\n",
            "λ (lambda_reg): 0.001\n",
            "τ (tau): 0.05\n",
            "γ (gamma): 0.001\n",
            "\n",
            "======================================================================\n",
            "TRAINING (NUMBA OPTIMIZED)\n",
            "======================================================================\n",
            "Note: First iteration may be slower due to JIT compilation...\n",
            "Iteration 1/15: Train RMSE = 0.8281, Test RMSE = 0.8635, NLL = 11714.73, Time = 49.86s\n",
            "Iteration 2/15: Train RMSE = 0.7328, Test RMSE = 0.8042, NLL = 10123.10, Time = 37.69s\n",
            "Iteration 3/15: Train RMSE = 0.7088, Test RMSE = 0.7865, NLL = 9789.86, Time = 37.11s\n",
            "Iteration 4/15: Train RMSE = 0.7010, Test RMSE = 0.7798, NLL = 9675.35, Time = 35.66s\n",
            "Iteration 5/15: Train RMSE = 0.6973, Test RMSE = 0.7764, NLL = 9613.77, Time = 36.91s\n",
            "Iteration 6/15: Train RMSE = 0.6951, Test RMSE = 0.7743, NLL = 9572.54, Time = 36.36s\n",
            "Iteration 7/15: Train RMSE = 0.6936, Test RMSE = 0.7729, NLL = 9541.32, Time = 35.39s\n",
            "Iteration 8/15: Train RMSE = 0.6926, Test RMSE = 0.7719, NLL = 9515.75, Time = 36.35s\n",
            "Iteration 9/15: Train RMSE = 0.6919, Test RMSE = 0.7712, NLL = 9493.66, Time = 36.25s\n",
            "Iteration 10/15: Train RMSE = 0.6914, Test RMSE = 0.7706, NLL = 9473.86, Time = 35.37s\n",
            "Iteration 11/15: Train RMSE = 0.6910, Test RMSE = 0.7702, NLL = 9455.66, Time = 36.12s\n",
            "Iteration 12/15: Train RMSE = 0.6906, Test RMSE = 0.7698, NLL = 9438.62, Time = 36.00s\n",
            "Iteration 13/15: Train RMSE = 0.6904, Test RMSE = 0.7695, NLL = 9422.48, Time = 35.44s\n",
            "Iteration 14/15: Train RMSE = 0.6902, Test RMSE = 0.7693, NLL = 9407.03, Time = 36.41s\n",
            "Iteration 15/15: Train RMSE = 0.6900, Test RMSE = 0.7691, NLL = 9392.15, Time = 35.42s\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE (NUMBA OPTIMIZED)\n",
            "======================================================================\n",
            "Final Train RMSE: 0.6900\n",
            "Final Test RMSE: 0.7691\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 3: Replace the \"Trying to vectorise training\" cell with this code\n",
        "# =============================================================================\n",
        "\n",
        "# HYPERPARAMETERS\n",
        "\n",
        "K = 32               # Number of latent factors\n",
        "num_iters = 15       # Number of ALS iterations\n",
        "lambda_reg = 0.001   # Regularization for latent factors (U, V)\n",
        "tau = 0.05           # Regularization term for user/item vectors\n",
        "gamma = 0.001        # Regularization for biases\n",
        "\n",
        "M = n_users          # Number of users\n",
        "N = n_movies         # Number of movies\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INITIALIZING ALS MODEL (NUMBA OPTIMIZED)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Users: {M:,}\")\n",
        "print(f\"Movies: {N:,}\")\n",
        "print(f\"Latent factors (K): {K}\")\n",
        "print(f\"Iterations: {num_iters}\")\n",
        "print(f\"λ (lambda_reg): {lambda_reg}\")\n",
        "print(f\"τ (tau): {tau}\")\n",
        "print(f\"γ (gamma): {gamma}\")\n",
        "\n",
        "# INITIALIZE BIASES AND LATENT FACTORS\n",
        "\n",
        "user_biases = np.zeros(M, dtype=np.float32)\n",
        "item_biases = np.zeros(N, dtype=np.float32)\n",
        "U = ((1/math.sqrt(K)) * np.random.randn(M, K)).astype(np.float32)   # User latent factors\n",
        "V = ((1/math.sqrt(K)) * np.random.randn(N, K)).astype(np.float32)   # Item latent factors\n",
        "\n",
        "# For plotting\n",
        "nll_history = []\n",
        "rmse_train_history = []\n",
        "rmse_test_history = []\n",
        "\n",
        "# ALS TRAINING LOOP (NUMBA OPTIMIZED)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING (NUMBA OPTIMIZED)\")\n",
        "print(\"=\"*70)\n",
        "print(\"Note: First iteration may be slower due to JIT compilation...\")\n",
        "\n",
        "import time\n",
        "\n",
        "for iter in range(num_iters):\n",
        "    iter_start = time.time()\n",
        "\n",
        "    # UPDATE ALL USERS (PARALLEL)\n",
        "    update_all_users_numba(\n",
        "        M, K, lambda_reg, tau, gamma,\n",
        "        user_biases, item_biases, U, V,\n",
        "        train_ratings_by_user,\n",
        "        user_train_start\n",
        "    )\n",
        "\n",
        "    # UPDATE ALL ITEMS (PARALLEL)\n",
        "    update_all_items_numba(\n",
        "        N, K, lambda_reg, tau, gamma,\n",
        "        user_biases, item_biases, U, V,\n",
        "        train_ratings_by_movie,\n",
        "        movie_train_start\n",
        "    )\n",
        "\n",
        "    # COMPUTE TRAINING METRICS (PARALLEL)\n",
        "    squared_error, count = compute_train_metrics_numba(\n",
        "        M, K,\n",
        "        user_biases, item_biases, U, V,\n",
        "        train_ratings_by_user,\n",
        "        user_train_start\n",
        "    )\n",
        "\n",
        "    # Regularization terms\n",
        "    reg_bias = np.sum(user_biases ** 2) + np.sum(item_biases ** 2)\n",
        "    reg_factors = np.sum(U ** 2) + np.sum(V ** 2)\n",
        "\n",
        "    # Log likelihood formula from slides\n",
        "    log_likelihood = -(lambda_reg / 2) * squared_error - (tau / 2) * reg_factors - (gamma / 2) * reg_bias\n",
        "\n",
        "    # Negative log likelihood (negate to get NLL)\n",
        "    nll = -log_likelihood\n",
        "    nll_history.append(nll)\n",
        "\n",
        "    # Training RMSE\n",
        "    rmse_train = np.sqrt(squared_error / count)\n",
        "    rmse_train_history.append(rmse_train)\n",
        "\n",
        "    # COMPUTE TEST RMSE (PARALLEL)\n",
        "    squared_error_test, count_test = compute_test_rmse_numba(\n",
        "        M, K,\n",
        "        user_biases, item_biases, U, V,\n",
        "        test_ratings_by_user,\n",
        "        user_test_start\n",
        "    )\n",
        "\n",
        "    rmse_test = np.sqrt(squared_error_test / count_test) if count_test > 0 else 0\n",
        "    rmse_test_history.append(rmse_test)\n",
        "\n",
        "    iter_time = time.time() - iter_start\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_iters}: \"\n",
        "          f\"Train RMSE = {rmse_train:.4f}, Test RMSE = {rmse_test:.4f}, \"\n",
        "          f\"NLL = {nll:.2f}, Time = {iter_time:.2f}s\")\n",
        "\n",
        "# PLOT RESULTS\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(nll_history, marker='o', color='purple')\n",
        "plt.title(\"Negative Log Likelihood (Training)\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Negative Log Likelihood\")\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(rmse_train_history, marker='o', color='orange')\n",
        "plt.title(\"Training RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(rmse_test_history, marker='o', color='green')\n",
        "plt.title(\"Test RMSE\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE (NUMBA OPTIMIZED)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Final Train RMSE: {rmse_train_history[-1]:.4f}\")\n",
        "print(f\"Final Test RMSE: {rmse_test_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4DQC5swj7rc"
      },
      "source": [
        "### Test with dummy user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sx0enY8tfNaK"
      },
      "outputs": [],
      "source": [
        "# helper function for movie name from movie_id\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "movies = pd.read_csv(\"ml-32m/movies.csv\")\n",
        "\n",
        "def get_movie_name(movie_id):\n",
        "    row = movies[movies[\"movieId\"] == movie_id]\n",
        "    return row.iloc[0][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuXpEXqgcC69",
        "outputId": "0f12a55d-3249-4d98-cead-248f682bdaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING DUMMY USER FOR RECOMMENDATIONS\n",
            "======================================================================\n",
            "Movie ID: 2\n",
            "Movie Index: 1\n",
            "Rating: 5.0\n",
            "\n",
            "======================================================================\n",
            "TRAINING DUMMY USER\n",
            "======================================================================\n",
            "Iteration 1/3: bias = 2.5284\n",
            "Iteration 2/3: bias = 2.1547\n",
            "Iteration 3/3: bias = 2.0994\n",
            "✓ Dummy user trained!\n",
            "  Final bias: 2.0994\n",
            "  Latent vector norm: 0.1908\n"
          ]
        }
      ],
      "source": [
        "# DUMMY USER SETUP\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING DUMMY USER FOR RECOMMENDATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Harry Potter movie (you can change this to any movie_id)\n",
        "harry_potter_movie_id = 2\n",
        "rating_value = 5.0\n",
        "\n",
        "# Get the movie index\n",
        "\n",
        "harry_potter_idx = data.movie_id_to_idx[harry_potter_movie_id]\n",
        "print(f\"Movie ID: {harry_potter_movie_id}\")\n",
        "print(f\"Movie Index: {harry_potter_idx}\")\n",
        "print(f\"Rating: {rating_value}\")\n",
        "\n",
        "# Dummy user's ratings: [(movie_idx, rating)]\n",
        "dummy_user_ratings = [(harry_potter_idx, rating_value)]\n",
        "\n",
        "# TRAIN DUMMY USER (3 ITERATIONS)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING DUMMY USER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize dummy user's parameters\n",
        "dummy_user_bias = 0.0\n",
        "dummy_user_latent = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "num_dummy_iters = 3\n",
        "\n",
        "for iter in range(num_dummy_iters):\n",
        "    # Update dummy user bias\n",
        "    bias_sum = 0\n",
        "    for movie_idx, rating in dummy_user_ratings:\n",
        "        pred = item_biases[movie_idx] + np.dot(dummy_user_latent, V[movie_idx])\n",
        "        residual = rating - pred\n",
        "        bias_sum += lambda_reg * residual\n",
        "\n",
        "    dummy_user_bias = bias_sum / (lambda_reg * len(dummy_user_ratings) + gamma)\n",
        "\n",
        "    # Update dummy user latent vector\n",
        "    A = np.zeros((K, K), dtype=np.float32)\n",
        "    b = np.zeros(K, dtype=np.float32)\n",
        "\n",
        "    for movie_idx, rating in dummy_user_ratings:\n",
        "        residual = rating - dummy_user_bias - item_biases[movie_idx]\n",
        "\n",
        "        A += lambda_reg * np.outer(V[movie_idx], V[movie_idx])\n",
        "        b += lambda_reg * residual * V[movie_idx]\n",
        "\n",
        "    A += tau * np.eye(K, dtype=np.float32)\n",
        "    dummy_user_latent = np.linalg.solve(A, b)\n",
        "\n",
        "    print(f\"Iteration {iter+1}/{num_dummy_iters}: bias = {dummy_user_bias:.4f}\")\n",
        "\n",
        "print(f\"✓ Dummy user trained!\")\n",
        "print(f\"  Final bias: {dummy_user_bias:.4f}\")\n",
        "print(f\"  Latent vector norm: {np.linalg.norm(dummy_user_latent):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TvCFBykcC96",
        "outputId": "b0372426-03c8-4d7e-c45b-667177156fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPUTING RECOMMENDATION SCORES\n",
            "======================================================================\n",
            "Filtering movies with fewer than 100 ratings...\n",
            "Movies with >= 100 ratings: 11,732/84,432\n",
            "\n",
            "======================================================================\n",
            "TOP 20 RECOMMENDATIONS\n",
            "======================================================================\n",
            "\n",
            "Rank   Movie ID     # Movie Title\n",
            "--------------------------------------------------\n",
            "1      3114         Toy Story 2 (1999)\n",
            "2      4886         Monsters, Inc. (2001)\n",
            "3      6377         Finding Nemo (2003)\n",
            "4      78499        Toy Story 3 (2010)\n",
            "5      8961         Incredibles, The (2004)\n",
            "6      364          Lion King, The (1994)\n",
            "7      4306         Shrek (2001)\n",
            "8      588          Aladdin (1992)\n",
            "9      2355         Bug's Life, A (1998)\n",
            "10     356          Forrest Gump (1994)\n",
            "11     68954        Up (2009)\n",
            "12     480          Jurassic Park (1993)\n",
            "13     595          Beauty and the Beast (1991)\n",
            "14     134853       Inside Out (2015)\n",
            "15     34           Babe (1995)\n",
            "16     8360         Shrek 2 (2004)\n",
            "17     50872        Ratatouille (2007)\n",
            "18     2028         Saving Private Ryan (1998)\n",
            "19     2081         Little Mermaid, The (1989)\n",
            "20     60069        WALL·E (2008)\n"
          ]
        }
      ],
      "source": [
        "# COMPUTE RECOMMENDATION SCORES\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPUTING RECOMMENDATION SCORES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Compute scores for all movies\n",
        "scores = np.zeros(N, dtype=np.float32)\n",
        "\n",
        "for n in range(N):\n",
        "    # Downweight item bias for better personalization\n",
        "    scores[n] = np.dot(dummy_user_latent, V[n]) + 0.05 * item_biases[n]\n",
        "\n",
        "# FILTER OUT LOW-RATED MOVIES\n",
        "\n",
        "print(\"Filtering movies with fewer than 100 ratings...\")\n",
        "\n",
        "# Count ratings per movie in training set\n",
        "movie_rating_counts = np.zeros(N, dtype=np.int32)\n",
        "for n in range(N):\n",
        "    movie_rating_counts[n] = movie_train_start[n+1] - movie_train_start[n]\n",
        "\n",
        "# Create mask for movies with >= 100 ratings\n",
        "popular_movies_mask = movie_rating_counts >= 100\n",
        "num_popular = np.sum(popular_movies_mask)\n",
        "\n",
        "print(f\"Movies with >= 100 ratings: {num_popular:,}/{N:,}\")\n",
        "\n",
        "# Set scores of unpopular movies to (-inf) so they don't appear in recommendations\n",
        "filtered_scores = scores.copy()\n",
        "filtered_scores[~popular_movies_mask] = -np.inf\n",
        "\n",
        "# GET TOP RECOMMENDATIONS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOP 20 RECOMMENDATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get top 20 movie indices\n",
        "filtered_scores[harry_potter_idx] = -np.inf  # Don't recommend the movie they already rated\n",
        "\n",
        "top_indices = np.argsort(filtered_scores)[::-1][:20]\n",
        "\n",
        "print(f\"\\n{'Rank':<6} {'Movie ID':<12} {'# Movie Title':<12}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for rank, movie_idx in enumerate(top_indices, 1):\n",
        "    movie_id = data.idx_to_movie_id[movie_idx]\n",
        "    movie_name = get_movie_name(movie_id)\n",
        "#   score = filtered_scores[movie_idx]\n",
        "#   num_ratings = movie_rating_counts[movie_idx]\n",
        "    print(f\"{rank:<6} {movie_id:<12} {movie_name:}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yEvebQydcc7"
      },
      "source": [
        "### Saving Model Parameters Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tgd2SRWBQt11"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('users_latent.pkl', 'wb') as file:\n",
        "    pickle.dump(U, file)\n",
        "with open('movies_latent.pkl', 'wb') as file:\n",
        "    pickle.dump(V, file)\n",
        "with open('users_biases.pkl', 'wb') as file:\n",
        "    pickle.dump(user_biases, file)\n",
        "with open('movies_biases.pkl', 'wb') as file:\n",
        "    pickle.dump(item_biases, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0SaWYYrfNaL"
      },
      "source": [
        "## Finding Most Polarizing Movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woMBKlI4ZqPi"
      },
      "outputs": [],
      "source": [
        "# 1. Count ratings per movie\n",
        "movie_rating_counts = np.zeros(N, dtype=int)\n",
        "for movie_idx in range(N):\n",
        "    start = movie_train_start[movie_idx]\n",
        "    end = movie_train_start[movie_idx + 1]\n",
        "    movie_rating_counts[movie_idx] = end - start\n",
        "\n",
        "# 2. Helper\n",
        "def has_enough_ratings(movie_idx, min_ratings=20):\n",
        "    return movie_rating_counts[movie_idx] >= min_ratings\n",
        "\n",
        "# 3. Norms\n",
        "movie_norms = np.linalg.norm(V, axis=1)\n",
        "sorted_desc = np.argsort(-movie_norms)   # descending\n",
        "top_10 = []\n",
        "\n",
        "for movie_idx in sorted_desc:\n",
        "    if has_enough_ratings(movie_idx):\n",
        "        movie_id = data.idx_to_movie_id[movie_idx]\n",
        "        title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
        "        top_10.append((title, movie_id, movie_norms[movie_idx]))\n",
        "        if len(top_10) == 10:\n",
        "            break\n",
        "\n",
        "print(\"\\n=== TOP 10 MOST POLARIZING MOVIES ===\")\n",
        "for title, movie_id, norm in top_10:\n",
        "    print(f\"{title:60s} | ID={movie_id:6d} | norm={norm:.4f}\")\n",
        "\n",
        "sorted_asc = np.argsort(movie_norms)   # ascending\n",
        "bottom_10 = []\n",
        "\n",
        "for movie_idx in sorted_asc:\n",
        "    if has_enough_ratings(movie_idx):\n",
        "        movie_id = data.idx_to_movie_id[movie_idx]\n",
        "        title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
        "        bottom_10.append((title, movie_id, movie_norms[movie_idx]))\n",
        "        if len(bottom_10) == 10:\n",
        "            break\n",
        "\n",
        "print(\"\\n=== BOTTOM 10 LEAST POLARIZING MOVIES ===\")\n",
        "for title, movie_id, norm in bottom_10:\n",
        "    print(f\"{title:60s} | ID={movie_id:6d} | norm={norm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jedi6glBfNaL"
      },
      "outputs": [],
      "source": [
        "# Helper function: get ratings for a movie\n",
        "def get_movie_train_ratings_array(movie_idx):\n",
        "    \"\"\"Return all training ratings for a movie as a numpy array\"\"\"\n",
        "    ratings = get_movie_train_ratings(movie_idx)[:, 1]  # column 1 = rating\n",
        "    return ratings\n",
        "\n",
        "# Compute rating variance for each movie\n",
        "movie_rating_var = np.zeros(N, dtype=np.float32)\n",
        "min_ratings = 20  # filter out unpopular movies\n",
        "\n",
        "for movie_idx in range(N):\n",
        "    ratings = get_movie_train_ratings_array(movie_idx)\n",
        "    if len(ratings) >= min_ratings:\n",
        "        movie_rating_var[movie_idx] = np.var(ratings)\n",
        "    else:\n",
        "        movie_rating_var[movie_idx] = -1  # ignore movies with too few ratings\n",
        "\n",
        "# Top 10 polarizing movies\n",
        "top_10_idx = np.argsort(-movie_rating_var)[:10]\n",
        "\n",
        "print(\"\\n=== TOP 10 POLARIZING MOVIES ===\")\n",
        "for idx in top_10_idx:\n",
        "    movie_id = data.idx_to_movie_id[idx]\n",
        "    title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
        "    var = movie_rating_var[idx]\n",
        "    print(f\"{title:60s} | movieId={movie_id:6d} | rating variance={var:.4f}\")\n",
        "\n",
        "# Bottom 10 least polarizing movies\n",
        "bottom_10_idx = np.argsort(movie_rating_var)[:10]\n",
        "\n",
        "print(\"\\n=== BOTTOM 10 LEAST POLARIZING MOVIES ===\")\n",
        "for idx in bottom_10_idx:\n",
        "    movie_id = data.idx_to_movie_id[idx]\n",
        "    title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
        "    var = movie_rating_var[idx]\n",
        "    print(f\"{title:60s} | movieId={movie_id:6d} | rating variance={var:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyr-kTk7fNaL"
      },
      "outputs": [],
      "source": [
        "# Correct if movies are rows\n",
        "movie_norms = np.linalg.norm(V, axis=1)\n",
        "\n",
        "# Correct if movies are columns\n",
        "movie_norms = np.linalg.norm(V, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY9qP4-xfNaM"
      },
      "outputs": [],
      "source": [
        "for idx, movie_id in enumerate([259351]):\n",
        "    print(movie_id, np.linalg.norm(V[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-H-cNEWfNaM"
      },
      "outputs": [],
      "source": [
        "movie_id = 356\n",
        "movie_idx = data.movie_id_to_idx[movie_id]\n",
        "norm_144436 = movie_norms[movie_idx]\n",
        "print(\"Norm for movieId 144436:\", norm_144436)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiSogrwBfNaM"
      },
      "outputs": [],
      "source": [
        "title = movies.loc[movies['movieId'] == movie_id, 'title'].values[0]\n",
        "print(f\"{title} (movieId={movie_id}) has norm = {norm_144436:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9kG-75d2a_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLjAmO_nfNaM"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "def plot_movie_embeddings(movie_ids, movies_latent, movies_biases, movie_to_idx, movies_df):\n",
        "    \"\"\"\n",
        "    Plots 2D embeddings of selected movies, scaled by movie biases.\n",
        "\n",
        "    Parameters:\n",
        "        movie_ids (list): List of movie IDs to plot\n",
        "        movies_latent (np.ndarray): Latent matrix V, shape (n_movies, k)\n",
        "        movies_biases (np.ndarray): Movie biases, shape (n_movies,)\n",
        "        movie_to_idx (dict): Mapping from movieId to row index in movies_latent\n",
        "        movies_df (pd.DataFrame): Movies dataframe with \"movieId\" and \"title\"\n",
        "    \"\"\"\n",
        "    # Extract latent vectors and biases\n",
        "    selected_vectors = np.array([movies_latent[movie_to_idx[movie_id], :] for movie_id in movie_ids])\n",
        "    selected_biases = np.array([movies_biases[movie_to_idx[movie_id]] for movie_id in movie_ids])\n",
        "\n",
        "    # Scale vectors to highlight movies with higher bias\n",
        "    scaled_vectors = selected_vectors * (1 + 0.05 * selected_biases[:, np.newaxis])\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    for i, movie_id in enumerate(movie_ids):\n",
        "        title = movies_df.loc[movies_df[\"movieId\"] == movie_id, \"title\"].iloc[0]\n",
        "        x, y = scaled_vectors[i, 0], scaled_vectors[i, 1]\n",
        "        plt.scatter(x, y, s=100, label=title)\n",
        "        plt.text(x + 0.01, y + 0.01, title, fontsize=9)  # offset for clarity\n",
        "\n",
        "    plt.title(\"2D Embeddings of Selected Movies (Scaled by Bias)\")\n",
        "    plt.xlabel(\"Latent Dimension 1\")\n",
        "    plt.ylabel(\"Latent Dimension 2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc=\"upper left\", fontsize=\"small\", bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"2d_embeddings.svg\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example movie IDs\n",
        "movie_ids = [78772, 72407, 91104, 8957,8368,364, 48, 588, 1022,207027,167780, 1688, 131739, 140115,1907, 5816, 40815, 595, 7153, 4993, 1,  39446, 48877, 55577]\n",
        "plot_movie_embeddings(movie_ids, V, item_biases, data.movie_id_to_idx, movies)\n",
        "\n",
        "\n",
        "def plot_movie_embeddings(movie_ids, movies_latent, movies_biases, movie_to_idx, movies_df):\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj9olJb7eU3s"
      },
      "source": [
        "### 2D Vector Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMZ-AzpffNaN"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Ensure inline plotting\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_movie_embeddings_pca(movie_ids, movies_latent, movies_biases, movie_to_idx, movies_df):\n",
        "    \"\"\"\n",
        "    Reduces latent dimensions to 2D using PCA and plots movie embeddings.\n",
        "\n",
        "    Parameters:\n",
        "        movie_ids (list): Movie IDs to visualize\n",
        "        movies_latent (np.ndarray): Latent matrix V (n_movies × k)\n",
        "        movies_biases (np.ndarray): Movie bias vector (n_movies,)\n",
        "        movie_to_idx (dict): Mapping from movieId -> row index in latent matrix\n",
        "        movies_df (pd.DataFrame): Movies dataframe (movieId, title)\n",
        "    \"\"\"\n",
        "\n",
        "    # ---- 1. PCA on full latent matrix ----\n",
        "    pca = PCA(n_components=2)\n",
        "    V_2d = pca.fit_transform(movies_latent)   # shape (n_movies, 2)\n",
        "\n",
        "    # ---- 2. Extract embeddings for selected movies ----\n",
        "    x_vals = []\n",
        "    y_vals = []\n",
        "    titles = []\n",
        "\n",
        "    for movie_id in movie_ids:\n",
        "        idx = movie_to_idx[movie_id]\n",
        "        x_vals.append(V_2d[idx, 0])\n",
        "        y_vals.append(V_2d[idx, 1])\n",
        "        titles.append(movies_df.loc[movies_df[\"movieId\"] == movie_id, \"title\"].iloc[0])\n",
        "\n",
        "    x_vals = np.array(x_vals)\n",
        "    y_vals = np.array(y_vals)\n",
        "\n",
        "    # ---- 3. Scaling points by bias (optional but cool) ----\n",
        "    selected_biases = np.array([movies_biases[movie_to_idx[m]] for m in movie_ids])\n",
        "    scale = 1 + 0.05 * selected_biases  # small bias-based scaling\n",
        "\n",
        "    # ---- 4. Plot ----\n",
        "    plt.figure(figsize=(22, 12))\n",
        "\n",
        "    for i, title in enumerate(titles):\n",
        "        plt.scatter(x_vals[i], y_vals[i], s=120 * scale[i], alpha=0.8)\n",
        "        plt.text(x_vals[i] + 0.01, y_vals[i] + 0.01, title, fontsize=9)\n",
        "\n",
        "    plt.title(\"Movie Embeddings (PCA Reduction to 2D)\", fontsize=16)\n",
        "    plt.xlabel(\"PCA Component 1\")\n",
        "    plt.ylabel(\"PCA Component 2\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "#    Optional: save (MOVED BEFORE plt.show())\n",
        "    plt.savefig(\"movie_embeddings_pca.svg\", format=\"svg\")\n",
        "\n",
        "    plt.show() # <--- Now display the plotPhilipp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz29dhG8fNaN"
      },
      "outputs": [],
      "source": [
        "\"\"\"movie_ids = [\n",
        "    78772, 72407, 91104, 8957, 8368,\n",
        "    364, 48, 588, 1022, 207027,\n",
        "    167780, 1688, 131739, 140115, 1907,\n",
        "    5816, 40815, 595, 7153, 4993,\n",
        "    1, 39446, 48877, 55577\n",
        "]\"\"\"\n",
        "movie_ids = [78772, 72407,1, 78499,3114, 91104, 98203, 8957, 39446, 48877, 55577]\n",
        "\n",
        "plot_movie_embeddings_pca(\n",
        "    movie_ids,\n",
        "    V,\n",
        "    item_biases,\n",
        "    data.movie_id_to_idx,\n",
        "    movies\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkMg8PllC3nk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4XsXQV65W3cS",
        "I0SaWYYrfNaL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
